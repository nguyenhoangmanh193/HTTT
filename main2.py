import streamlit as st
import pandas as pd
import requests
import re
import numpy as np
from io import BytesIO
from PIL import Image
from process_data import clean_up_pipeline
import xlsxwriter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.dates as mdates
from model.model_title import model_title
from model.model_information import model_info
from model.model_football import model_football
import os
import datetime

# API_KEY = "AIzaSyANUWlnh43MDqZ3SS0DqCRiR8ns_5aP5DY"
API_KEY = "AIzaSyDTfRpLGpiImpanOKYi81MAdpIIC5uUTeU"

YOUTUBE_API_URL = "https://www.googleapis.com/youtube/v3/channels"
YOUTUBE_VIDEO_API_URL = "https://www.googleapis.com/youtube/v3/search"
YOUTUBE_COMMENTS_API_URL = "https://www.googleapis.com/youtube/v3/commentThreads"


def get_channel_id(url):
    try:
        response = requests.get(url)
        if response.status_code != 200:
            return None
        match = re.search(r'"externalId":"(UC[\w-]+)"', response.text)
        return match.group(1) if match else None
    except Exception as e:
        st.error(f"L·ªói khi l·∫•y channel ID: {str(e)}")
        return None


def get_recent_videos(channel_id):
    """L·∫•y 20 video g·∫ßn nh·∫•t c·ªßa k√™nh."""
    try:
        params = {
            "part": "snippet",
            "channelId": channel_id,
            "maxResults": 50,
            "order": "date",
            "type": "video",
            "key": API_KEY
        }
        response = requests.get(YOUTUBE_VIDEO_API_URL, params=params)
        data = response.json()

        if "items" not in data:
            return []

        videos = []
        video_ids = []

        for item in data["items"]:
            video_id = item["id"]["videoId"]
            video_ids.append(video_id)
            videos.append({
                "channel_name": item["snippet"]["channelTitle"],
                "title": item["snippet"]["title"],
                "published_date": item["snippet"]["publishedAt"],
                "id": video_id,
                "link": f"https://www.youtube.com/watch?v={video_id}"
            })

        # G·ªçi API ƒë·ªÉ l·∫•y s·ªë l∆∞·ª£t xem v√† s·ªë b√¨nh lu·∫≠n
        stats_url = "https://www.googleapis.com/youtube/v3/videos"
        stats_params = {
            "part": "statistics",
            "id": ",".join(video_ids),
            "key": API_KEY
        }
        stats_response = requests.get(stats_url, params=stats_params)
        stats_data = stats_response.json()

        stats_dict = {item["id"]: item["statistics"] for item in stats_data.get("items", [])}

        for v in videos:
            vid = v["id"]
            v["views"] = int(stats_dict.get(vid, {}).get("viewCount", 0))
            v["comments"] = int(stats_dict.get(vid, {}).get("commentCount", 0))

        return videos
    except Exception as e:
        st.error(f"L·ªói khi l·∫•y danh s√°ch video: {str(e)}")
        return []


def get_all_comments(video_id, channel_id, video_title):
    """L·∫•y to√†n b·ªô b√¨nh lu·∫≠n t·ª´ video, bao g·ªìm c·∫£ ph·∫£n h·ªìi (replies)."""
    try:
        comments_list = []
        next_page_token = None

        while True:
            params = {
                "part": "snippet,replies",
                "videoId": video_id,
                "maxResults": 100,
                "textFormat": "plainText",
                "key": API_KEY
            }
            if next_page_token:
                params["pageToken"] = next_page_token

            response = requests.get(YOUTUBE_COMMENTS_API_URL, params=params)
            comments_data = response.json()

            if "items" in comments_data:
                for item in comments_data["items"]:
                    # Top-level comment
                    comment_snippet = item["snippet"]["topLevelComment"]["snippet"]
                    comments_list.append({
                        "channel_id": channel_id,
                        "video_id": video_id,
                        "video_title": video_title,
                        "author": comment_snippet["authorDisplayName"],
                        "comment": comment_snippet["textDisplay"],
                        "publishedAt": comment_snippet["publishedAt"],
                        "is_reply": False,
                        "reply_to": None
                    })

                    # N·∫øu c√≥ ph·∫£n h·ªìi (replies) th√¨ duy·ªát th√™m
                    if "replies" in item:
                        for reply in item["replies"]["comments"]:
                            reply_snippet = reply["snippet"]
                            comments_list.append({
                                "channel_id": channel_id,
                                "video_id": video_id,
                                "video_title": video_title,
                                "author": reply_snippet["authorDisplayName"],
                                "comment": reply_snippet["textDisplay"],
                                "publishedAt": reply_snippet["publishedAt"],
                                "is_reply": True,
                                "reply_to": comment_snippet["authorDisplayName"]
                            })

            next_page_token = comments_data.get("nextPageToken")
            if not next_page_token:
                break

        return comments_list
    except Exception as e:
        st.error(f"L·ªói khi l·∫•y b√¨nh lu·∫≠n: {str(e)}")
        return []


def crawl(url_channel):
    """Crawl th√¥ng tin k√™nh v√† danh s√°ch video."""
    try:
        channel_id = get_channel_id(url_channel)
        if not channel_id:
            st.error("Kh√¥ng t√¨m th·∫•y channel ID!")
            return None

        params = {"part": "snippet,statistics", "id": channel_id, "key": API_KEY}
        response = requests.get(YOUTUBE_API_URL, params=params)
        data = response.json()

        if "items" not in data or not data["items"]:
            st.error("Kh√¥ng t√¨m th·∫•y th√¥ng tin k√™nh!")
            return None

        channel_info = data["items"][0]
        snippet = channel_info["snippet"]
        stats = channel_info["statistics"]

        recent_videos = get_recent_videos(channel_id)

        return {
            "Created": snippet.get("publishedAt", "N/A")[:10],
            "Country": snippet.get("country", "N/A"),
            "Subscribers": int(stats.get("subscriberCount", 0)),
            "Total_videos": int(stats.get("videoCount", 0)),
            "Avatar": snippet["thumbnails"]["high"]["url"] if "thumbnails" in snippet else None,
            "Description": snippet.get("description", "Kh√¥ng c√≥ m√¥ t·∫£"),
            "List_id": channel_id,
            "Recent_videos": recent_videos
        }
    except Exception as e:
        st.error(f"L·ªói khi crawl d·ªØ li·ªáu: {str(e)}")
        return None


def save(file_csv):
    df = pd.DataFrame([file_csv])  # Chuy·ªÉn dictionary th√†nh DataFrame
    csv_bytes = BytesIO()
    df.to_csv(csv_bytes, index=False, encoding="utf-8-sig")  # L∆∞u file v·ªõi UTF-8 (h·ªó tr·ª£ ti·∫øng Vi·ªát)
    csv_bytes.seek(0)
    return csv_bytes


def profile_overview(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    return {
        "Created": df['Created'].iloc[0] if 'Created' in df.columns else "N/A",
        "Add_to_ViralStat": df['Add_to_ViralStat'].iloc[0] if 'Add_to_ViralStat' in df.columns else "N/A",
        "Country": df['Country'].iloc[0] if 'Country' in df.columns else "N/A",
        "Subscribers": df['Subscribers'].iloc[0] if 'Subscribers' in df.columns else 0,
        "Total_videos": df['Total_videos'].iloc[0] if 'Total_videos' in df.columns else 0
    }


def profile_stats(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    return {
        "Subscribers": df['Subscribers'].sum() if 'Subscribers' in df.columns else 0,
        "Total_view": df['Total_view'].sum() if 'Total_view' in df.columns else 0,
        "Avg": df['Avg'].mean() if 'Avg' in df.columns else 0
    }


def analyze_comments(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    # Placeholder for comment analysis logic
    return {
        "Positive_comments": df['Positive_comments'].sum() if 'Positive_comments' in df.columns else 0,
        "Negative_comments": df['Negative_comments'].sum() if 'Negative_comments' in df.columns else 0,
        "Neutral_comments": df['Neutral_comments'].sum() if 'Neutral_comments' in df.columns else 0
    }


def recommend_videos(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    # Placeholder for recommendation logic
    return {
        "Recommended_videos": ["Video1", "Video2", "Video3"]  # Example recommendations
    }


def delete_old_files(folder_path):
    """X√≥a t·∫•t c·∫£ file trong th∆∞ m·ª•c data"""
    for file in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
        except Exception as e:
            print(f"L·ªói khi x√≥a file {file_path}: {e}")


def main():
    st.set_page_config(layout="wide")
    st.sidebar.title("Ch·ª©c nƒÉng")
    page = st.sidebar.radio("Ch·ªçn trang", ["Crawl", "Statistical", "ƒê·ªÅ xu·∫•t"])

    if page == "Crawl":
        st.title("Crawl d·ªØ li·ªáu")
        url = st.text_input("Nh·∫≠p URL k√™nh")

        if st.button("T√¨m ki·∫øm"):
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
                st.session_state["channel_data"] = crawl(url)
                if st.session_state["channel_data"] is None:
                    st.error("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!")
                    st.stop()

        # N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu k√™nh
        if "channel_data" in st.session_state:
            data = st.session_state["channel_data"]

            # Hi·ªÉn th·ªã th√¥ng tin k√™nh
            col1, col2 = st.columns([1, 3])
            with col1:
                if data["Avatar"]:
                    try:
                        response = requests.get(data["Avatar"])
                        image = Image.open(BytesIO(response.content))
                        st.image(image, width=100)
                    except Exception as e:
                        st.error(f"Kh√¥ng th·ªÉ t·∫£i ·∫£nh ƒë·∫°i di·ªán: {str(e)}")
            with col2:
                st.write(f"**Created:** {data['Created']}")
                st.write(f"**Country:** {data['Country']}")
                st.write(f"**Subscribers:** {data['Subscribers']:,}")
                st.write(f"**Total Videos:** {data['Total_videos']:,}")
                st.write(f"**Description:** {data['Description']}")

            # Hi·ªÉn th·ªã danh s√°ch video
            st.write("**Danh s√°ch video g·∫ßn nh·∫•t**")
            if "Recent_videos" not in st.session_state:
                st.session_state["Recent_videos"] = data["Recent_videos"]

            df_videos = pd.DataFrame(st.session_state["Recent_videos"])
            if not df_videos.empty:
                st.dataframe(df_videos[["title", "published_date", "views", "comments", "link"]])

                # Dropdown ch·ªçn video
                video_ids = [video["id"] for video in st.session_state["Recent_videos"]]
                selected_video_id = st.selectbox(
                    "Ch·ªçn video ƒë·ªÉ xem b√¨nh lu·∫≠n:",
                    video_ids,
                    format_func=lambda vid: next(
                        v["title"] for v in st.session_state["Recent_videos"] if v["id"] == vid
                    )
                )

                # Hi·ªÉn th·ªã th√¥ng tin video ƒë√£ ch·ªçn
                selected_video = next(
                    (v for v in st.session_state["Recent_videos"] if v["id"] == selected_video_id),
                    None
                )
                if selected_video:
                    st.write(f"**Ti√™u ƒë·ªÅ video:** {selected_video['title']}")
                    st.write(f"**L∆∞·ª£t xem:** {selected_video['views']:,}")
                    st.write(f"**S·ªë b√¨nh lu·∫≠n:** {selected_video['comments']:,}")

                    # L·∫•y b√¨nh lu·∫≠n
                    if "video_comments" not in st.session_state or st.session_state["video_comments"][
                        "video_id"] != selected_video_id:
                        with st.spinner("ƒêang t·∫£i b√¨nh lu·∫≠n..."):
                            st.session_state["video_comments"] = {
                                "video_id": selected_video_id,
                                "comments": get_all_comments(
                                    selected_video_id,
                                    data['List_id'],
                                    selected_video['title']
                                )
                            }

                    # Hi·ªÉn th·ªã b√¨nh lu·∫≠n
                    df_comments = pd.DataFrame(st.session_state["video_comments"]["comments"])
                    if not df_comments.empty:
                        df_comments['clean_comment'] = df_comments['comment'].apply(clean_up_pipeline)
                        st.dataframe(df_comments[["author", "comment", "publishedAt", "is_reply", "reply_to"]])

                # N√∫t l·∫•y to√†n b·ªô comment
                if st.button("L·∫•y to√†n b·ªô b√¨nh lu·∫≠n c·ªßa t·∫•t c·∫£ video"):
                    all_comments = []
                    progress_bar = st.progress(0)
                    total_videos = len(st.session_state["Recent_videos"])

                    for i, video in enumerate(st.session_state["Recent_videos"]):
                        with st.spinner(f"ƒêang t·∫£i b√¨nh lu·∫≠n video {i + 1}/{total_videos}..."):
                            comments = get_all_comments(video["id"], data["List_id"], video["title"])
                            all_comments.extend(comments)
                        progress_bar.progress((i + 1) / total_videos)

                    st.session_state["all_video_comments"] = all_comments
                    st.success("ƒê√£ l·∫•y xong to√†n b·ªô b√¨nh lu·∫≠n!")

                # Hi·ªÉn th·ªã v√† t·∫£i xu·ªëng d·ªØ li·ªáu
                if "all_video_comments" in st.session_state:
                    df_all_comments = pd.DataFrame(st.session_state["all_video_comments"])
                    if not df_all_comments.empty:
                        st.write("### To√†n b·ªô b√¨nh lu·∫≠n c·ªßa t·∫•t c·∫£ c√°c video")
                        st.dataframe(df_all_comments[
                                         ["video_title", "author", "comment", "publishedAt", "is_reply", "reply_to"]])

                        # T·∫£i v·ªÅ Excel tr·ª±c ti·∫øp khi b·∫•m n√∫t
                        excel_bytes = BytesIO()
                        with pd.ExcelWriter(excel_bytes, engine="xlsxwriter") as writer:
                            # Sheet 1 - Th√¥ng tin k√™nh
                            channel_info_df = pd.DataFrame([{
                                "Ng√†y t·∫°o": data["Created"],
                                "Qu·ªëc gia": data["Country"],
                                "L∆∞·ª£t ƒëƒÉng k√Ω": data["Subscribers"],
                                "T·ªïng s·ªë video": data["Total_videos"],
                                "M√¥ t·∫£ k√™nh": data["Description"]
                            }])
                            channel_info_df.to_excel(writer, sheet_name="Th√¥ng tin k√™nh", index=False)

                            # Sheet 2 - Danh s√°ch video g·∫ßn ƒë√¢y
                            df_videos.to_excel(writer, sheet_name="Video g·∫ßn ƒë√¢y", index=False)

                            # Sheet 3 - Danh s√°ch b√¨nh lu·∫≠n
                            df_all_comments['clean_comment'] = df_all_comments['comment'].apply(clean_up_pipeline)
                            df_all_comments.to_excel(writer, sheet_name="B√¨nh lu·∫≠n", index=False)

                        excel_bytes.seek(0)
                        st.download_button(
                            label="üì• T·∫£i file Excel t·ªïng h·ª£p (.xlsx)",
                            data=excel_bytes,
                            file_name="youtube_data.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

    elif page == "Statistical":
        st.title("Th·ªëng k√™ Ph√¢n t√≠ch YouTube")
        uploaded_file = st.file_uploader("T·∫£i l√™n file Excel (.xlsx)", type=["xlsx"])

        if uploaded_file:
            video_data = pd.read_excel(uploaded_file, sheet_name="Video g·∫ßn ƒë√¢y")
            channel_info = pd.read_excel(uploaded_file, sheet_name="Th√¥ng tin k√™nh")
            video_comment = pd.read_excel(uploaded_file, sheet_name="B√¨nh lu·∫≠n")

            video_comment['clean_comment'] = video_comment['clean_comment'].astype(str)

            #################
            cleaned = clean_up_pipeline(channel_info['M√¥ t·∫£ k√™nh'][0])
            label, words = model_title.classify_sentiment(cleaned)
            st.write(label)
            # st.write(words)
            if label == '0':
                video_comment['label'] = video_comment['clean_comment'].apply(
                    lambda x: model_football.classify_sentiment(x)[0])
            else:
                video_comment['label'] = video_comment['clean_comment'].apply(
                    lambda x: model_info.classify_sentiment(x)[0])

            ##################
            video_data['published_date'] = pd.to_datetime(video_data['published_date'])
            video_data['title_length'] = video_data['title'].apply(lambda x: len(str(x)))
            video_data['comment_view_ratio'] = video_data['comments'] / video_data['views']
            video_data['month'] = video_data['published_date'].dt.to_period('M')
            video_data['week'] = video_data['published_date'].dt.to_period('W')
            video_data['day'] = video_data['published_date'].dt.to_period('D')
            video_data['short_title'] = video_data['title'].apply(lambda x: (x[:40] + '...') if len(str(x)) > 40 else x)

            # D√≤ng ti√™u ƒë·ªÅ v·ªõi ch·ªØ tr√°i - ph·∫£i
            c1, c2 = st.columns([1, 1])

            with c1:
                st.markdown("### üìä T·ªïng quan k√™nh")

            with c2:
                st.markdown("### üîç Theo d√µi")

            tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs(
                ["T·ªïng quan", "Ph·ªï bi·∫øn", "T·ª∑ l·ªá t∆∞∆°ng t√°c", "Hi·ªáu su·∫•t", "Ph√¢n nh√≥m", "T·ªâ l·ªá t·ªïng quan",
                 'T·ªâ l·ªá theo th·ªùi gian', "Top video vi ph·∫°m",
                 "ƒê√°nh gi√° t·ªïng th·ªÉ"])

            with tab1:
                st.subheader("Th√¥ng tin k√™nh")
                st.write(f"**Ng√†y t·∫°o:** {channel_info.iloc[0]['Ng√†y t·∫°o']}")
                st.write(f"**Qu·ªëc gia:** {channel_info.iloc[0]['Qu·ªëc gia']}")
                st.write(f"**L∆∞·ª£t ƒëƒÉng k√Ω:** {channel_info.iloc[0]['L∆∞·ª£t ƒëƒÉng k√Ω']:,}")
                st.write(f"**T·ªïng s·ªë video:** {channel_info.iloc[0]['T·ªïng s·ªë video']:,}")
                st.write(f"**M√¥ t·∫£:** {channel_info.iloc[0]['M√¥ t·∫£ k√™nh']}")

            with tab2:
                st.markdown("## üìä So s√°nh Top 10 Videos (M·ªü r·ªông ngang, ch·ªØ nh·ªè)")

                col1, col2 = st.columns([1, 1])  # gi·ªØ nguy√™n chia 2 c·ªôt b·∫±ng nhau

                with col1:
                    st.markdown("### üëÅÔ∏è Views")
                    top10_views = video_data.sort_values(by='views', ascending=False).head(10)
                    fig1 = plt.figure(figsize=(7, 3))  # r·ªông h∆°n, th·∫•p h∆°n
                    sns.barplot(data=top10_views, y='short_title', x='views', palette='Blues_r')
                    plt.title('Top 10 by Views', fontsize=10)
                    plt.xlabel('Views', fontsize=9)
                    plt.ylabel('')
                    plt.xticks(fontsize=8)
                    plt.yticks(fontsize=7)
                    plt.tight_layout()
                    st.pyplot(fig1)

                with col2:
                    st.markdown("### üí¨ Comments")
                    top10_comments = video_data.sort_values(by='comments', ascending=False).head(10)
                    fig2 = plt.figure(figsize=(7, 3))  # r·ªông h∆°n, th·∫•p h∆°n
                    sns.barplot(data=top10_comments, y='short_title', x='comments', palette='Oranges_r')
                    plt.title('Top 10 by Comments', fontsize=10)
                    plt.xlabel('Comments', fontsize=9)
                    plt.ylabel('')
                    plt.xticks(fontsize=8)
                    plt.yticks(fontsize=7)
                    plt.tight_layout()
                    st.pyplot(fig2)

            with tab3:
                with st.expander("Theo b√¨nh lu·∫≠n v√† l∆∞·ª£t xem"):
                    st.markdown("### Bubble chart: Views vs Comments (Size = Comments/Views)")

                    # T·∫°o layout v·ªõi 2 c·ªôt
                    col1, col2 = st.columns([7, 3])  # C·ªôt b√™n tr√°i chi·∫øm 50% v√† c·ªôt b√™n ph·∫£i chi·∫øm 50%

                    # --- C·ªôt 1: Bi·ªÉu ƒë·ªì Bubble Chart ---
                    with col1:
                        plt.figure(figsize=(10, 6))  # K√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
                        sizes = ((video_data['comments'] / video_data['views']) * 300000).clip(10, 5000)
                        plt.scatter(video_data['views'], video_data['comments'], s=sizes, alpha=0.5, edgecolors='w')

                        for i in range(len(video_data)):
                            short_title = video_data['short_title'].iloc[i]
                            plt.annotate(short_title,
                                         (video_data['views'].iloc[i], video_data['comments'].iloc[i]),
                                         fontsize=8, alpha=0.6)

                        plt.title('Bubble Chart: Views vs Comments (Size = Comments/Views)', fontsize=12)
                        plt.xlabel('Views', fontsize=10)
                        plt.ylabel('Comments', fontsize=10)
                        plt.grid(True)
                        plt.tight_layout()
                        st.pyplot(plt)
                        # T·∫°o ƒë∆∞·ªùng k·∫ª ph√¢n c√°ch gi·ªØa hai c·ªôt
                    st.markdown(
                        """
                        <style>
                        .divider {
                            border-left: 2px solid #D3D3D3;
                            height: 100%;
                            margin-left: 10px;
                            margin-right: 10px;
                        }
                        </style>
                        """, unsafe_allow_html=True
                    )
                    st.markdown("<div class='divider'></div>", unsafe_allow_html=True)
                    # --- C·ªôt 2: Hi·ªÉn th·ªã ch·ªØ "Sl" ---
                    with col2:
                        st.markdown("### Sl")
                        st.write("ƒê√¢y l√† ph·∫ßn d√†nh cho ch·ªØ 'Sl'. B·∫°n c√≥ th·ªÉ thay ƒë·ªïi n·ªôi dung theo y√™u c·∫ßu.")

                with st.expander("T·ªâ l·ªá t∆∞∆°ng t√°c theo ƒë·ªô d√†i ti√™u ƒë·ªÅ"):
                    st.markdown("### Scatter: Title length vs Comments/Views")

                    # T·∫°o layout v·ªõi 2 c·ªôt, bi·ªÉu ƒë·ªì chi·∫øm 70%, ch·ªØ "Sl" chi·∫øm 30%
                    col1, col2 = st.columns([7, 3])  # C·ªôt b√™n tr√°i chi·∫øm 70% v√† c·ªôt b√™n ph·∫£i chi·∫øm 30%

                    # --- C·ªôt 1: Bi·ªÉu ƒë·ªì Scatter ---
                    with col1:
                        video_data['comment_view_ratio'] = video_data['comments'] / video_data['views']

                        plt.figure(figsize=(10, 6))  # K√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
                        sns.scatterplot(data=video_data, x='title_length', y='comment_view_ratio', color='green',
                                        marker='o')

                        plt.title('Title Length vs Comment/View Ratio', fontsize=12)
                        plt.xlabel('Title Length', fontsize=10)
                        plt.ylabel('Comment/View Ratio', fontsize=10)
                        plt.grid(True)
                        plt.tight_layout()
                        st.pyplot(plt)

                    # --- C·ªôt 2: Hi·ªÉn th·ªã ch·ªØ "Sl" ---
                    with col2:
                        # Th√™m ƒë∆∞·ªùng ph√¢n c√°ch gi·ªØa c·ªôt 1 v√† c·ªôt 2
                        st.markdown(
                            """
                            <style>
                            .divider {
                                border-left: 2px solid #D3D3D3;
                                height: 100%;
                                margin-left: 10px;
                                margin-right: 10px;
                            }
                            </style>
                            """, unsafe_allow_html=True
                        )
                        st.markdown("<div class='divider'></div>", unsafe_allow_html=True)  # Hi·ªÉn th·ªã ƒë∆∞·ªùng ph√¢n c√°ch

                        # N·ªôi dung c·ªôt 2
                        st.markdown("### Sl")
                        st.write("ƒê√¢y l√† ph·∫ßn d√†nh cho ch·ªØ 'Sl'. B·∫°n c√≥ th·ªÉ thay ƒë·ªïi n·ªôi dung theo y√™u c·∫ßu.")

            with tab4:
                st.markdown("### üìä Ph√¢n t√≠ch s·ªë video v√† l∆∞·ª£t t∆∞∆°ng t√°c theo th·ªùi gian")
                # --- 6. S·ªë video theo th√°ng, tu·∫ßn, ng√†y ---

                # Monthly stats (c√≥ ƒë·∫ßy ƒë·ªß th√°ng)
                st.markdown("")
                full_month_range = pd.period_range(start=video_data['month'].min(), end=video_data['month'].max(),
                                                   freq='M')
                monthly_stats = video_data.groupby('month').agg({
                    'title': 'count',
                    'views': 'sum',
                    'comments': 'sum'
                }).rename(columns={'title': 'video_count'})
                monthly_stats = monthly_stats.reindex(full_month_range, fill_value=0)

                # Weekly stats (c√≥ ƒë·∫ßy ƒë·ªß tu·∫ßn)
                full_week_range = pd.period_range(start=video_data['week'].min(), end=video_data['week'].max(),
                                                  freq='W')
                weekly_stats = video_data.groupby('week').agg({
                    'title': 'count',
                    'views': 'sum',
                    'comments': 'sum'
                }).rename(columns={'title': 'video_count'})
                weekly_stats = weekly_stats.reindex(full_week_range, fill_value=0)

                # Daily stats (c√≥ ƒë·∫ßy ƒë·ªß ng√†y)
                full_day_range = pd.period_range(start=video_data['day'].min(), end=video_data['day'].max(), freq='D')
                daily_stats = video_data.groupby('day').agg({
                    'title': 'count',
                    'views': 'sum',
                    'comments': 'sum'
                }).rename(columns={'title': 'video_count'})

                daily_stats = daily_stats.reindex(full_day_range, fill_value=0)
                # üéØ T√≠nh trung b√¨nh views/comments CH·ªà CHO NH·ªÆNG NG√ÄY C√ì VIDEO
                # (kh√¥ng d√πng reindex)

                monthly_avg = monthly_stats[monthly_stats['video_count'] > 0]
                weekly_avg = weekly_stats[weekly_stats['video_count'] > 0]
                daily_avg = daily_stats[daily_stats['video_count'] > 0]

                monthly_avg['avg_views_per_video'] = monthly_avg['views'] / monthly_avg['video_count']
                weekly_avg['avg_views_per_video'] = weekly_avg['views'] / weekly_avg['video_count']
                daily_avg['avg_views_per_video'] = daily_avg['views'] / daily_avg['video_count']

                monthly_avg['avg_comments_per_video'] = monthly_avg['comments'] / monthly_avg['video_count']
                weekly_avg['avg_comments_per_video'] = weekly_avg['comments'] / weekly_avg['video_count']
                daily_avg['avg_comments_per_video'] = daily_avg['comments'] / daily_avg['video_count']

                # S·ªë video theo ng√†y

                # --- Expander: Th·ªëng k√™ theo ng√†y ---
                with st.expander("üìÖ Th·ªëng k√™ theo ng√†y", expanded=False):
                    st.markdown("S·ªë video tr√™n ng√†y")
                    plt.figure(figsize=(20, 6))
                    ax = daily_stats['video_count'].plot(kind='bar', color='lightcoral')
                    plt.title('Number of Videos per Day')
                    plt.tight_layout()
                    st.pyplot(plt)

                    # --- Daily ---
                    st.markdown("S·ªë views tr√™n ng√†y")
                    daily_stats_nonzero = daily_stats[daily_stats['video_count'] > 0].copy()
                    daily_stats_nonzero['avg_views_per_video'] = daily_stats_nonzero['views'] / daily_stats_nonzero[
                        'video_count']
                    fig, ax = plt.subplots(figsize=(20, 6))
                    ax.plot(daily_stats_nonzero.index.to_timestamp(), daily_stats_nonzero['avg_views_per_video'],
                            marker='o', color='green', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Views per Video per Day')
                    plt.xlabel('Day')
                    plt.ylabel('Avg Views per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Daily ---
                    st.markdown("S·ªë comments tr√™n ng√†y")
                    daily_stats_nonzero['avg_comments_per_video'] = daily_stats_nonzero['comments'] / \
                                                                    daily_stats_nonzero[
                                                                        'video_count']
                    fig, ax = plt.subplots(figsize=(20, 6))
                    ax.plot(daily_stats_nonzero.index.to_timestamp(), daily_stats_nonzero['avg_comments_per_video'],
                            marker='o', color='red', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Comments per Video per Day')
                    plt.xlabel('Day')
                    plt.ylabel('Avg Comments per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Expander: Th·ªëng k√™ theo tu·∫ßn ---
                with st.expander("üìà Th·ªëng k√™ theo tu·∫ßn", expanded=False):
                    # 6.2 Weekly - S·ªë video theo tu·∫ßn
                    st.markdown("S·ªë video tr√™n tu·∫ßn")
                    plt.figure(figsize=(14, 6))
                    ax = weekly_stats['video_count'].plot(kind='bar', color='lightgreen')
                    plt.title('Number of Videos per Week')
                    plt.tight_layout()
                    st.pyplot(plt)

                    # --- Weekly ---
                    st.markdown("S·ªë views tr√™n tu·∫ßn")
                    weekly_stats_nonzero = weekly_stats[weekly_stats['video_count'] > 0].copy()
                    weekly_stats_nonzero['avg_views_per_video'] = weekly_stats_nonzero['views'] / weekly_stats_nonzero[
                        'video_count']
                    fig, ax = plt.subplots(figsize=(14, 6))
                    ax.plot(weekly_stats_nonzero.index.to_timestamp(), weekly_stats_nonzero['avg_views_per_video'],
                            marker='o', color='blue', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Views per Video per Week')
                    plt.xlabel('Week')
                    plt.ylabel('Avg Views per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Weekly ---
                    st.markdown("S·ªë comments tr√™n tu·∫ßn")
                    weekly_stats_nonzero['avg_comments_per_video'] = weekly_stats_nonzero['comments'] / \
                                                                     weekly_stats_nonzero['video_count']
                    fig, ax = plt.subplots(figsize=(14, 6))
                    ax.plot(weekly_stats_nonzero.index.to_timestamp(), weekly_stats_nonzero['avg_comments_per_video'],
                            marker='o', color='purple', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Comments per Video per Week')
                    plt.xlabel('Week')
                    plt.ylabel('Avg Comments per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)
                    # --- Expander: Th·ªëng k√™ theo th√°ng ---
                with st.expander("üóìÔ∏è Th·ªëng k√™ theo th√°ng", expanded=False):
                    # 6.1 Monthly - S·ªë video theo th√°ng
                    st.markdown("S·ªë video tr√™n th√°ng")
                    plt.figure(figsize=(10, 5))
                    ax = monthly_stats['video_count'].plot(kind='bar', color='skyblue')
                    plt.title('Number of Videos per Month')
                    plt.tight_layout()
                    st.pyplot(plt)

                    # --- Monthly ---
                    st.markdown("S·ªë Views tr√™n th√°ng")
                    monthly_stats_nonzero = monthly_stats[monthly_stats['video_count'] > 0].copy()
                    monthly_stats_nonzero['avg_views_per_video'] = monthly_stats_nonzero['views'] / \
                                                                   monthly_stats_nonzero[
                                                                       'video_count']
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(monthly_stats_nonzero.index.to_timestamp(), monthly_stats_nonzero['avg_views_per_video'],
                            marker='o', color='orange', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.MonthLocator())
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
                    plt.xticks(rotation=45)
                    plt.title('Average Views per Video per Month')
                    plt.xlabel('Month')
                    plt.ylabel('Avg Views per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Monthly ---
                    st.markdown("S·ªë comments tr√™n th√°ng")
                    monthly_stats_nonzero['avg_comments_per_video'] = monthly_stats_nonzero['comments'] / \
                                                                      monthly_stats_nonzero['video_count']
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(monthly_stats_nonzero.index.to_timestamp(), monthly_stats_nonzero['avg_comments_per_video'],
                            marker='o', color='green', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.MonthLocator())
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
                    plt.xticks(rotation=45)
                    plt.title('Average Comments per Video per Month')
                    plt.xlabel('Month')
                    plt.ylabel('Avg Comments per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

            with tab5:
                st.markdown("KMeans Clustering: Views vs Comments")
                features = video_data[['views', 'comments']]
                scaler = StandardScaler()
                scaled_features = scaler.fit_transform(features)
                kmeans = KMeans(n_clusters=4, random_state=42)
                video_data['cluster'] = kmeans.fit_predict(scaled_features)

                plt.figure(figsize=(10, 6))
                sns.scatterplot(data=video_data, x='views', y='comments', hue='cluster', palette='Set2')
                plt.title('KMeans Clustering')
                st.pyplot(plt)

                st.markdown("""
                **Nh√≥m ph√¢n lo·∫°i:**
                - Nh√≥m 0: View cao, comment cao
                - Nh√≥m 1: View cao, comment th·∫•p
                - Nh√≥m 2: View th·∫•p, comment cao
                - Nh√≥m 3: View th·∫•p, comment th·∫•p
                """)

            with tab6:
                st.markdown("B·∫£ng ")
                st.subheader("D·ªØ li·ªáu b·∫£ng B√¨nh lu·∫≠n")
                st.write(label)

                # T√≠nh to√°n s·ªë l∆∞·ª£ng c√°c gi√° tr·ªã trong c·ªôt 'label'
                label_counts = video_comment['label'].value_counts().sort_index()
                labels = ['T√≠ch c·ª±c' if i == 'b√¨nh th∆∞·ªùng' else 'Ti√™u c·ª±c' for i in label_counts.index]

                # T·∫°o layout 2 c·ªôt
                col1, col2 = st.columns(2)

                with col1:
                    # Bi·ªÉu ƒë·ªì tr√≤n trong c·ªôt b√™n tr√°i
                    fig, ax = plt.subplots(figsize=(2.5, 2.5))  # ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc t√πy √Ω
                    ax.pie(label_counts, labels=labels, autopct='%.1f%%',
                           colors=['#66b3ff', '#ff6666'], startangle=140, textprops={'fontsize': 5})
                    ax.set_title('T·ª∑ l·ªá c·∫£m x√∫c', fontsize=7)
                    st.pyplot(fig)

                with col2:
                    # Ph·∫ßn ch·ªØ ho·∫∑c n·ªôi dung b√™n ph·∫£i
                    st.markdown("### Ph√¢n t√≠ch c·∫£m x√∫c")
                    st.write(
                        "Bi·ªÉu ƒë·ªì b√™n tr√°i th·ªÉ hi·ªán t·ª∑ l·ªá ph·∫ßn trƒÉm c√°c b√¨nh lu·∫≠n t√≠ch c·ª±c v√† ti√™u c·ª±c. "
                        "D·ª±a v√†o d·ªØ li·ªáu, b·∫°n c√≥ th·ªÉ nh·∫≠n bi·∫øt s·ª± ph√¢n b·ªë c·∫£m x√∫c trong t·∫≠p b√¨nh lu·∫≠n."
                    )

            with tab7:

                # ƒê·∫£m b·∫£o c·ªôt 'publishedAt' l√† ki·ªÉu datetime
                video_comment['publishedAt'] = pd.to_datetime(video_comment['publishedAt'])

                # T·∫°o c·ªôt "3 ng√†y"
                video_comment['3_days'] = video_comment['publishedAt'].dt.to_period('D').apply(
                    lambda r: r.start_time).dt.floor(
                    'D') + pd.to_timedelta(video_comment['publishedAt'].dt.day // 3 * 3, unit='D')

                # ƒê·∫øm s·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo kho·∫£ng 3 ng√†y v√† nh√£n
                count_by_3_days = video_comment.groupby(['3_days', 'label']).size().unstack(fill_value=0)

                col1, col2 = st.columns([3, 2])  # 3 ph·∫ßn cho bi·ªÉu ƒë·ªì, 2 ph·∫ßn cho n·ªôi dung kh√°c (t·ªïng = 5 -> 60%)

                with col1:
                    fig, ax = plt.subplots(figsize=(6, 4))
                    count_by_3_days.plot(kind='bar', ax=ax, color=['#66b3ff', '#ff6666'])

                    ax.set_xlabel('Ng√†y (M·ªói 3 ng√†y)', fontsize=8)
                    ax.set_ylabel('S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n', fontsize=8)
                    ax.set_title('S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo m·ªói 3 ng√†y v√† nh√£n (0: B√¨nh th∆∞·ªùng, 1: Toxic)', fontsize=9)
                    ax.tick_params(axis='x', labelrotation=45, labelsize=7)
                    ax.tick_params(axis='y', labelsize=7)
                    ax.legend(title='Label', labels=count_by_3_days.columns.astype(str), fontsize=7, title_fontsize=8)

                    plt.tight_layout()
                    st.pyplot(fig)

                with col2:
                    st.markdown("### Th·ªëng k√™")
                    st.markdown("- Bi·ªÉu ƒë·ªì th·ªÉ hi·ªán s·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo t·ª´ng kho·∫£ng 3 ng√†y.")
                    st.markdown("- M√†u xanh: B√¨nh th∆∞·ªùng, M√†u ƒë·ªè: Toxic.")

            with tab8:
                # T√≠nh t·ªïng s·ªë b√¨nh lu·∫≠n v√† s·ªë b√¨nh lu·∫≠n c√≥ label != 0 theo t·ª´ng video
                total_by_video = video_comment.groupby('video_title').size()
                toxic_by_video = video_comment[video_comment['label'] != 'b√¨nh th∆∞·ªùng'].groupby('video_title').size()

                # T√≠nh t·ª∑ l·ªá % v√† ch·ªçn top 10 video c√≥ t·ª∑ l·ªá toxic cao nh·∫•t
                toxic_percent = (toxic_by_video / total_by_video * 100).fillna(0)
                top10_videos = toxic_percent.sort_values(ascending=False).head(10)

                # Layout chia 2 c·ªôt: 60% - 40%
                col1, col2 = st.columns([3, 2])

                with col1:
                    fig, ax = plt.subplots(figsize=(6, 4))
                    ax.bar(range(1, 11), top10_videos.values, color='#ff6666')
                    ax.set_xticks(range(1, 11))
                    ax.set_xticklabels(range(1, 11))
                    ax.set_ylabel('T·ª∑ l·ªá % b√¨nh lu·∫≠n toxic', fontsize=9)
                    ax.set_title('Top 10 video c√≥ t·ª∑ l·ªá b√¨nh lu·∫≠n toxic cao nh·∫•t', fontsize=10)
                    ax.tick_params(labelsize=8)
                    plt.tight_layout()
                    st.pyplot(fig)

                with col2:
                    st.markdown("**Danh s√°ch video t∆∞∆°ng ·ª©ng:**")
                    video_labels = top10_videos.index.tolist()
                    for i, title in enumerate(video_labels, start=1):
                        st.markdown(f"{i}. {title}")

            with tab9:

                # T√≠nh t·ªïng s·ªë b√¨nh lu·∫≠n v√† s·ªë b√¨nh lu·∫≠n c√≥ label != 0 theo t·ª´ng video
                total_by_video = video_comment.groupby('video_title').size()
                toxic_by_video = video_comment[video_comment['label'] != 'b√¨nh th∆∞·ªùng'].groupby('video_title').size()

                # T√≠nh t·ª∑ l·ªá % v√† x√°c ƒë·ªãnh video n√†o c√≥ t·ª∑ l·ªá toxic > 11%
                toxic_percent = (toxic_by_video / total_by_video * 100).fillna(0)

                # ƒê√°nh d·∫•u video ti√™u c·ª±c (t·ª∑ l·ªá toxic > 11%)
                toxic_videos = toxic_percent[toxic_percent > 11].index
                non_toxic_videos = toxic_percent[toxic_percent <= 11].index

                # T·∫°o m·ªôt Series v·ªõi c√°c video ti√™u c·ª±c v√† kh√¥ng ti√™u c·ª±c
                video_labels = ['Ti√™u c·ª±c' if video in toxic_videos else 'Kh√¥ng ti√™u c·ª±c' for video in
                                video_comment['video_title']]
                labels_count = pd.Series(video_labels).value_counts()

                # T·∫°o layout 2 c·ªôt v·ªõi t·ª∑ l·ªá 3:2 (60% v√† 40%)
                col1, col2 = st.columns([1, 1])

                with col1:
                    fig, ax = plt.subplots(figsize=(3, 3))
                    ax.pie(labels_count, labels=labels_count.index, autopct='%1.1f%%', startangle=90,
                           colors=['#ff6666', '#66b3ff'])
                    ax.set_title('T·ª∑ l·ªá video ti√™u c·ª±c vs kh√¥ng ti√™u c·ª±c', fontsize=10)
                    plt.tight_layout()
                    st.pyplot(fig)

                with col2:
                    st.markdown("**Ph√¢n lo·∫°i video:**")
                    for label, count in labels_count.items():
                        st.markdown(f"- **{label}**: {count} video")



    elif page == "ƒê·ªÅ xu·∫•t":
        st.title("ƒê·ªÅ xu·∫•t video")

        # X√ìA ph·∫ßn t·∫£i l√™n file Excel
        # uploaded_file = st.file_uploader("T·∫£i l√™n file Excel (.xlsx)", type=["xlsx"])
        # if uploaded_file:
        #     recommendation_data = recommend_videos(uploaded_file)
        #     st.markdown("**Video Recommendations**")
        #     for video in recommendation_data["Recommended_videos"]:
        #         st.text(video)

        st.markdown("---")
        st.subheader("üì• Crawl v√† ƒë·ªÅ xu·∫•t t·ª´ 5 k√™nh c·ªë ƒë·ªãnh")

        excel_path = os.path.join("data", "all_channels_comments.xlsx")
        df_all_comments = None
        if os.path.exists(excel_path):
            try:
                df_all_comments = pd.read_excel(excel_path)
            except Exception as e:
                st.warning(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file Excel: {e}")

        # Hi·ªÉn th·ªã d·ªØ li·ªáu t·ª´ file n·∫øu c√≥
        if df_all_comments is not None and not df_all_comments.empty:
            # L·∫•y danh s√°ch k√™nh
            channel_names = df_all_comments[
                'channel_name'].unique().tolist() if 'channel_name' in df_all_comments.columns else []
            selected_channel = st.selectbox("Ch·ªçn k√™nh", channel_names)
            df_channel = df_all_comments[df_all_comments['channel_name'] == selected_channel]
            # L·∫•y danh s√°ch video
            video_titles = df_channel['video_title'].unique().tolist() if 'video_title' in df_channel.columns else []
            selected_video = st.selectbox("Ch·ªçn video", video_titles)
            df_video = df_channel[df_channel['video_title'] == selected_video]
            st.markdown("### B√¨nh lu·∫≠n c·ªßa video ƒë√£ ch·ªçn")
            st.dataframe(df_video)
        else:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu. H√£y b·∫•m 'C·∫≠p nh·∫≠t d·ªØ li·ªáu' ƒë·ªÉ crawl m·ªõi.")

        youtube_channels = {
            "BLV Anh Qu√¢n": "https://www.youtube.com/@blvanhquan68",
            "BLV Mai Anh T√†i": "https://www.youtube.com/@blvmaianhtai",
            "C·∫£m B√≥ng ƒê√°": "https://www.youtube.com/c/C%E1%BA%A3mB%C3%B3ng%C4%90%C3%A1",
            "BLV Anh Qu√¢n Stories": "https://www.youtube.com/@blvanhquanstories5371",
            "DaFootball VN": "https://www.youtube.com/@DaFootballVN"
        }

        if st.button("üîÑ C·∫≠p nh·∫≠t d·ªØ li·ªáu"):
            all_videos = {}
            channel_info_list = []
            all_comments = []
            for name, url in youtube_channels.items():
                channel_id = get_channel_id(url)
                if not channel_id:
                    continue
                videos = get_recent_videos(channel_id)[:20]
                all_videos[name] = {
                    "channel_id": channel_id,
                    "videos": videos
                }
                channel_data = crawl(f"https://www.youtube.com/channel/{channel_id}")
                channel_info_list.append({
                    "T√™n k√™nh": name,
                    "Ng√†y t·∫°o": channel_data["Created"] if channel_data else '',
                    "Qu·ªëc gia": channel_data["Country"] if channel_data else '',
                    "L∆∞·ª£t ƒëƒÉng k√Ω": channel_data["Subscribers"] if channel_data else '',
                    "T·ªïng s·ªë video": channel_data["Total_videos"] if channel_data else '',
                    "M√¥ t·∫£ k√™nh": channel_data["Description"] if channel_data else ''
                })
                for v in videos:
                    comments = get_all_comments(v["id"], channel_id, v["title"])
                    for c in comments:
                        c["channel_name"] = name
                        all_comments.append(c)
            st.session_state["all_videos"] = all_videos
            folder_path = os.path.abspath("data")
            os.makedirs(folder_path, exist_ok=True)
            delete_old_files(folder_path)
            excel_filename = "all_channels_comments.xlsx"
            excel_path = os.path.join(folder_path, excel_filename)
            df_all_comments = pd.DataFrame(all_comments)
            crawl_columns = [
                "channel_name", "channel_id", "video_id", "video_title", "author", "comment", "publishedAt", "is_reply",
                "reply_to"
            ]
            for col in crawl_columns:
                if col not in df_all_comments.columns:
                    df_all_comments[col] = ''
            df_all_comments = df_all_comments[crawl_columns]
            with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:
                df_all_comments.to_excel(writer, sheet_name="B√¨nh lu·∫≠n", index=False)
            st.success(f"ƒê√£ l∆∞u to√†n b·ªô b√¨nh lu·∫≠n c·ªßa 5 k√™nh v√†o file: {excel_filename}")
            st.rerun()


if __name__ == "__main__":
    main()