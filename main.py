import streamlit as st
import pandas as pd
import requests
import re
from io import BytesIO
from PIL import Image
from process_data import clean_up_pipeline
import xlsxwriter

API_KEY = "AIzaSyANUWlnh43MDqZ3SS0DqCRiR8ns_5aP5DY"
YOUTUBE_API_URL = "https://www.googleapis.com/youtube/v3/channels"
YOUTUBE_VIDEO_API_URL = "https://www.googleapis.com/youtube/v3/search"
YOUTUBE_COMMENTS_API_URL = "https://www.googleapis.com/youtube/v3/commentThreads"


def get_channel_id(url):
    response = requests.get(url)
    if response.status_code != 200:
        return None
    match = re.search(r'"externalId":"(UC[\w-]+)"', response.text)
    return match.group(1) if match else None


def get_recent_videos(channel_id):
    """L·∫•y 20 video g·∫ßn nh·∫•t c·ªßa k√™nh."""
    params = {
        "part": "snippet",
        "channelId": channel_id,
        "maxResults": 20,
        "order": "date",
        "type": "video",
        "key": API_KEY
    }
    response = requests.get(YOUTUBE_VIDEO_API_URL, params=params)
    data = response.json()

    if "items" not in data:
        return []

    videos = []
    video_ids = []

    for item in data["items"]:
        video_id = item["id"]["videoId"]
        video_ids.append(video_id)
        videos.append({
            "channel_name": item["snippet"]["channelTitle"],
            "title": item["snippet"]["title"],
            "published_date": item["snippet"]["publishedAt"],
            "id": video_id,
            "link": f"https://www.youtube.com/watch?v={video_id}"
        })

    # G·ªçi API ƒë·ªÉ l·∫•y s·ªë l∆∞·ª£t xem v√† s·ªë b√¨nh lu·∫≠n
    stats_url = "https://www.googleapis.com/youtube/v3/videos"
    stats_params = {
        "part": "statistics",
        "id": ",".join(video_ids),
        "key": API_KEY
    }
    stats_response = requests.get(stats_url, params=stats_params)
    stats_data = stats_response.json()

    stats_dict = {item["id"]: item["statistics"] for item in stats_data.get("items", [])}

    for v in videos:
        vid = v["id"]
        v["views"] = stats_dict.get(vid, {}).get("viewCount", "N/A")
        v["comments"] = stats_dict.get(vid, {}).get("commentCount", "N/A")

    return videos


def get_all_comments(video_id, channel_id, video_title):
    """L·∫•y to√†n b·ªô b√¨nh lu·∫≠n t·ª´ video, bao g·ªìm c·∫£ ph·∫£n h·ªìi (replies)."""
    comments_list = []
    next_page_token = None

    while True:
        params = {
            "part": "snippet,replies",
            "videoId": video_id,
            "maxResults": 100,
            "textFormat": "plainText",
            "key": API_KEY
        }
        if next_page_token:
            params["pageToken"] = next_page_token

        response = requests.get(YOUTUBE_COMMENTS_API_URL, params=params)
        comments_data = response.json()

        if "items" in comments_data:
            for item in comments_data["items"]:
                # Top-level comment
                comment_snippet = item["snippet"]["topLevelComment"]["snippet"]
                comments_list.append({
                    "channel_id": channel_id,
                    "video_id": video_id,
                    "video_title": video_title,
                    "author": comment_snippet["authorDisplayName"],
                    "comment": comment_snippet["textDisplay"],
                    "publishedAt": comment_snippet["publishedAt"],
                    "is_reply": False,
                    "reply_to": None
                })

                # N·∫øu c√≥ ph·∫£n h·ªìi (replies) th√¨ duy·ªát th√™m
                if "replies" in item:
                    for reply in item["replies"]["comments"]:
                        reply_snippet = reply["snippet"]
                        comments_list.append({
                            "channel_id": channel_id,
                            "video_id": video_id,
                            "video_title": video_title,
                            "author": reply_snippet["authorDisplayName"],
                            "comment": reply_snippet["textDisplay"],
                            "publishedAt": reply_snippet["publishedAt"],
                            "is_reply": True,
                            "reply_to": comment_snippet["authorDisplayName"]  # ai ƒë∆∞·ª£c reply t·ªõi
                        })

        next_page_token = comments_data.get("nextPageToken")
        if not next_page_token:
            break

    return comments_list


# C·∫≠p nh·∫≠t ph·∫ßn crawl ƒë·ªÉ hi·ªÉn th·ªã th√¥ng tin b√¨nh lu·∫≠n
def crawl(url_channel):
    """Crawl th√¥ng tin k√™nh v√† danh s√°ch video."""
    channel_id = get_channel_id(url_channel)
    if not channel_id:
        return None

    params = {"part": "snippet,statistics", "id": channel_id, "key": API_KEY}
    response = requests.get(YOUTUBE_API_URL, params=params)
    data = response.json()

    if "items" not in data or not data["items"]:
        return None

    channel_info = data["items"][0]
    snippet = channel_info["snippet"]
    stats = channel_info["statistics"]

    recent_videos = get_recent_videos(channel_id)

    return {
        "Created": snippet.get("publishedAt", "N/A")[:10],
        "Country": snippet.get("country", "N/A"),
        "Subscribers": int(stats.get("subscriberCount", 0)),
        "Total_videos": int(stats.get("videoCount", 0)),
        "Avatar": snippet["thumbnails"]["high"]["url"] if "thumbnails" in snippet else None,
        "Description": snippet.get("description", "Kh√¥ng c√≥ m√¥ t·∫£"),
        "List_id": channel_id,
        "Recent_videos": recent_videos
    }


def save(file_csv):
    df = pd.DataFrame([file_csv])  # Chuy·ªÉn dictionary th√†nh DataFrame
    csv_bytes = BytesIO()
    df.to_csv(csv_bytes, index=False, encoding="utf-8-sig")  # L∆∞u file v·ªõi UTF-8 (h·ªó tr·ª£ ti·∫øng Vi·ªát)
    csv_bytes.seek(0)
    return csv_bytes


def profile_overview(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    return {
        "Created": df['Created'].iloc[0] if 'Created' in df.columns else "N/A",
        "Add_to_ViralStat": df['Add_to_ViralStat'].iloc[0] if 'Add_to_ViralStat' in df.columns else "N/A",
        "Country": df['Country'].iloc[0] if 'Country' in df.columns else "N/A",
        "Subscribers": df['Subscribers'].iloc[0] if 'Subscribers' in df.columns else 0,
        "Total_videos": df['Total_videos'].iloc[0] if 'Total_videos' in df.columns else 0
    }


def profile_stats(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    return {
        "Subscribers": df['Subscribers'].sum() if 'Subscribers' in df.columns else 0,
        "Total_view": df['Total_view'].sum() if 'Total_view' in df.columns else 0,
        "Avg": df['Avg'].mean() if 'Avg' in df.columns else 0
    }


def analyze_comments(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    # Placeholder for comment analysis logic
    return {
        "Positive_comments": df['Positive_comments'].sum() if 'Positive_comments' in df.columns else 0,
        "Negative_comments": df['Negative_comments'].sum() if 'Negative_comments' in df.columns else 0,
        "Neutral_comments": df['Neutral_comments'].sum() if 'Neutral_comments' in df.columns else 0
    }


def recommend_videos(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    # Placeholder for recommendation logic
    return {
        "Recommended_videos": ["Video1", "Video2", "Video3"]  # Example recommendations
    }


def main():
    st.set_page_config(layout="wide")
    st.sidebar.title("Ch·ª©c nƒÉng")
    page = st.sidebar.radio("Ch·ªçn trang", ["T·ªïng quan", "Crawl", "Statistical", "Ph√¢n t√≠ch comment", "ƒê·ªÅ xu·∫•t"])

    if page == "T·ªïng quan":
        st.title("T·ªïng quan")
        uploaded_file = st.file_uploader("T·∫£i l√™n file CSV", type=["csv"])
        if uploaded_file:
            df = pd.read_csv(uploaded_file)
            st.dataframe(df)

    elif page == "Crawl":
        st.title("Crawl d·ªØ li·ªáu")
        url = st.text_input("Nh·∫≠p URL k√™nh")

        if st.button("T√¨m ki·∫øm"):
            st.session_state["channel_data"] = crawl(url)
            if st.session_state["channel_data"] is None:
                st.error("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!")
                st.stop()

        # N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu k√™nh
        if "channel_data" in st.session_state:
            data = st.session_state["channel_data"]

            col1, col2 = st.columns([1, 3])
            with col1:
                if data["Avatar"]:
                    response = requests.get(data["Avatar"])
                    image = Image.open(BytesIO(response.content))
                    st.image(image, width=100)
            with col2:
                st.write(f"**Created:** {data['Created']}")
                st.write(f"**Country:** {data['Country']}")
                st.write(f"**Subscribers:** {data['Subscribers']}")
                st.write(f"**Total Videos:** {data['Total_videos']}")
                st.write(f"**Description:** {data['Description']}")
            st.write("**Danh s√°ch 20 video g·∫ßn nh·∫•t**")
            # üü¢ L∆∞u danh s√°ch video v√†o session_state ƒë·ªÉ tr√°nh reload m·∫•t d·ªØ li·ªáu
            if "Recent_videos" not in st.session_state:
                st.session_state["Recent_videos"] = data["Recent_videos"]

            df_videos = pd.DataFrame(st.session_state["Recent_videos"])
            # üü¢ Th√™m ph·∫ßn t·∫£i v·ªÅ CSV

            # üü¢ Dropdown ch·ªçn video
            video_ids = [video["id"] for video in st.session_state["Recent_videos"]]
            selected_video_id = st.selectbox("Ch·ªçn video:", video_ids, format_func=lambda vid: next(
                v["title"] for v in st.session_state["Recent_videos"] if v["id"] == vid))

            # üü¢ Hi·ªÉn th·ªã th√¥ng tin video ƒë√£ ch·ªçn
            selected_video = next(v for v in st.session_state["Recent_videos"] if v["id"] == selected_video_id)
            st.write(f"**Ti√™u ƒë·ªÅ video:** {selected_video['title']}")
            st.write(f"**L∆∞·ª£t xem:** {selected_video['views']}")
            st.write(f"**S·ªë b√¨nh lu·∫≠n:** {selected_video['comments']}")

            # üü¢ L·∫•y b√¨nh lu·∫≠n ch·ªâ khi ch∆∞a c√≥
            if "video_comments" not in st.session_state or st.session_state["video_comments"][
                "video_id"] != selected_video_id:
                st.session_state["video_comments"] = {"video_id": selected_video_id,
                                                      "comments": get_all_comments(selected_video_id, data['List_id'],
                                                                                   selected_video['title'])}

            # üü¢ Hi·ªÉn th·ªã b√¨nh lu·∫≠n
            df_comments = pd.DataFrame(st.session_state["video_comments"]["comments"])
            df_comments['clean_comment'] = df_comments['comment'].apply(clean_up_pipeline)
            st.dataframe(df_comments)

            # üü¢ Th√™m ph·∫ßn t·∫£i v·ªÅ CSV

            # üü¢ N√∫t l·∫•y to√†n b·ªô comment c·ªßa t·∫•t c·∫£ video
            if st.button("L·∫•y to√†n b·ªô b√¨nh lu·∫≠n c·ªßa 20 video"):
                all_comments = []
                for video in st.session_state["Recent_videos"]:
                    comments = get_all_comments(video["id"], data["List_id"], video["title"])
                    all_comments.extend(comments)

                # L∆∞u to√†n b·ªô comment v√†o session
                st.session_state["all_video_comments"] = all_comments
                st.success("ƒê√£ l·∫•y xong to√†n b·ªô b√¨nh lu·∫≠n!")

            # üü¢ Hi·ªÉn th·ªã b·∫£ng to√†n b·ªô b√¨nh lu·∫≠n n·∫øu c√≥
            if "all_video_comments" in st.session_state:
                df_all_comments = pd.DataFrame(st.session_state["all_video_comments"])

                if not df_all_comments.empty:
                    st.write("### To√†n b·ªô b√¨nh lu·∫≠n c·ªßa t·∫•t c·∫£ c√°c video")
                    st.dataframe(df_all_comments)

                    # T·∫£i v·ªÅ CSV
            if st.button("üì• T·∫£i file Excel t·ªïng h·ª£p (.xlsx)"):
                excel_bytes = BytesIO()
                with pd.ExcelWriter(excel_bytes, engine="xlsxwriter") as writer:
                    # Sheet 1 - Th√¥ng tin k√™nh
                    channel_info_df = pd.DataFrame([{
                        "Ng√†y t·∫°o": data["Created"],
                        "Qu·ªëc gia": data["Country"],
                        "L∆∞·ª£t ƒëƒÉng k√Ω": data["Subscribers"],
                        "T·ªïng s·ªë video": data["Total_videos"],
                        "M√¥ t·∫£ k√™nh": data["Description"]
                    }])
                    channel_info_df.to_excel(writer, sheet_name="Th√¥ng tin k√™nh", index=False)

                    # Sheet 2 - Danh s√°ch video g·∫ßn ƒë√¢y
                    df_videos.to_excel(writer, sheet_name="Video g·∫ßn ƒë√¢y", index=False)

                    # Sheet 3 - Danh s√°ch b√¨nh lu·∫≠n (∆∞u ti√™n l·∫•y to√†n b·ªô n·∫øu c√≥)
                    df_all_comments = pd.DataFrame(
                        st.session_state["all_video_comments"]
                    ) if "all_video_comments" in st.session_state else df_comments
                    df_all_comments['clean_comment'] = df_all_comments['comment'].apply(clean_up_pipeline)
                    df_all_comments.to_excel(writer, sheet_name="B√¨nh lu·∫≠n", index=False)

                excel_bytes.seek(0)
                st.download_button(
                    label="üìÑ T·∫£i xu·ªëng file Excel",
                    data=excel_bytes,
                    file_name="youtube_data.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    elif page == "Statistical":
        st.title("Th·ªëng k√™")
        uploaded_file = st.file_uploader("T·∫£i l√™n file CSV", type=["csv"])
        if uploaded_file:
            overview_data = profile_overview(uploaded_file)
            stats_data = profile_stats(uploaded_file)

            st.markdown("**Profile Overview**")
            st.text(f"Created: {overview_data['Created']}")
            st.text(f"Added to ViralStat: {overview_data['Add_to_ViralStat']}")
            st.text(f"Country: {overview_data['Country']}")
            st.text(f"Subscribers: {overview_data['Subscribers']}")
            st.text(f"Total_videos: {overview_data['Total_videos']}")

            st.markdown("**Profile Stats**")
            st.text(f"Subscribers: {stats_data['Subscribers']}")
            st.text(f"Total_view: {stats_data['Total_view']}")
            st.text(f"Avg: {stats_data['Avg']}")

    elif page == "Ph√¢n t√≠ch comment":
        st.title("Ph√¢n t√≠ch comment")
        uploaded_file = st.file_uploader("T·∫£i l√™n file CSV", type=["csv"])
        if uploaded_file:
            df = pd.read_csv(uploaded_file)

            # G·ªçi h√†m ti·ªÅn x·ª≠ l√Ω t·ª´ tienxuly.py
            df_processed = main(df)

            # Hi·ªÉn th·ªã k·∫øt qu·∫£ sau x·ª≠ l√Ω
            st.dataframe(df_processed)

            # T·∫£i xu·ªëng n·∫øu mu·ªën
            csv = df_processed.to_csv(index=False, encoding="utf-8-sig")
            st.download_button("T·∫£i file k·∫øt qu·∫£", data=csv, file_name="processed_comments.csv", mime="text/csv")

    elif page == "ƒê·ªÅ xu·∫•t":
        st.title("ƒê·ªÅ xu·∫•t video")
        uploaded_file = st.file_uploader("T·∫£i l√™n file CSV", type=["csv"])
        if uploaded_file:
            recommendation_data = recommend_videos(uploaded_file)

            st.markdown("**Video Recommendations**")
            for video in recommendation_data["Recommended_videos"]:
                st.text(video)


if __name__ == "__main__":
    main()