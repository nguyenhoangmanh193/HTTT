import streamlit as st
import pandas as pd
import requests
import re
import numpy as np
from io import BytesIO
from PIL import Image
from process_data import clean_up_pipeline
import xlsxwriter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.dates as mdates
from model.model_title import model_title
from model.model_information import  model_info
from  model.model_football import model_football

#API_KEY = "AIzaSyANUWlnh43MDqZ3SS0DqCRiR8ns_5aP5DY"
API_KEY = "AIzaSyByJ01WdcsbNk53ifHvLiSrUCxAcjwuaZ4"

YOUTUBE_API_URL = "https://www.googleapis.com/youtube/v3/channels"
YOUTUBE_VIDEO_API_URL = "https://www.googleapis.com/youtube/v3/search"
YOUTUBE_COMMENTS_API_URL = "https://www.googleapis.com/youtube/v3/commentThreads"


def get_channel_id(url):
    response = requests.get(url)
    if response.status_code != 200:
        return None
    match = re.search(r'"externalId":"(UC[\w-]+)"', response.text)
    return match.group(1) if match else None


def get_recent_videos(channel_id):
    """L·∫•y 20 video g·∫ßn nh·∫•t c·ªßa k√™nh."""
    params = {
        "part": "snippet",
        "channelId": channel_id,
        "maxResults": 50,
        "order": "date",
        "type": "video",
        "key": API_KEY
    }
    response = requests.get(YOUTUBE_VIDEO_API_URL, params=params)
    data = response.json()

    if "items" not in data:
        return []

    videos = []
    video_ids = []


    for item in data["items"]:
        video_id = item["id"]["videoId"]
        video_ids.append(video_id)
        videos.append({
            "channel_name": item["snippet"]["channelTitle"],
            "title": item["snippet"]["title"],
            "published_date": item["snippet"]["publishedAt"],
            "id": video_id,
            "link": f"https://www.youtube.com/watch?v={video_id}"
        })

    # G·ªçi API ƒë·ªÉ l·∫•y s·ªë l∆∞·ª£t xem v√† s·ªë b√¨nh lu·∫≠n
    stats_url = "https://www.googleapis.com/youtube/v3/videos"
    stats_params = {
        "part": "statistics",
        "id": ",".join(video_ids),
        "key": API_KEY
    }
    stats_response = requests.get(stats_url, params=stats_params)
    stats_data = stats_response.json()

    stats_dict = {item["id"]: item["statistics"] for item in stats_data.get("items", [])}

    for v in videos:
        vid = v["id"]
        v["views"] = stats_dict.get(vid, {}).get("viewCount", "N/A")
        v["comments"] = stats_dict.get(vid, {}).get("commentCount", "N/A")

    return videos


def get_all_comments(video_id, channel_id, video_title):
    """L·∫•y to√†n b·ªô b√¨nh lu·∫≠n t·ª´ video, bao g·ªìm c·∫£ ph·∫£n h·ªìi (replies)."""
    comments_list = []
    next_page_token = None

    while True:
        params = {
            "part": "snippet,replies",
            "videoId": video_id,
            "maxResults": 100,
            "textFormat": "plainText",
            "key": API_KEY
        }
        if next_page_token:
            params["pageToken"] = next_page_token

        response = requests.get(YOUTUBE_COMMENTS_API_URL, params=params)
        comments_data = response.json()

        if "items" in comments_data:
            for item in comments_data["items"]:
                # Top-level comment
                comment_snippet = item["snippet"]["topLevelComment"]["snippet"]
                comments_list.append({
                    "channel_id": channel_id,
                    "video_id": video_id,
                    "video_title": video_title,
                    "author": comment_snippet["authorDisplayName"],
                    "comment": comment_snippet["textDisplay"],
                    "publishedAt": comment_snippet["publishedAt"],
                    "is_reply": False,
                    "reply_to": None
                })

                # N·∫øu c√≥ ph·∫£n h·ªìi (replies) th√¨ duy·ªát th√™m
                if "replies" in item:
                    for reply in item["replies"]["comments"]:
                        reply_snippet = reply["snippet"]
                        comments_list.append({
                            "channel_id": channel_id,
                            "video_id": video_id,
                            "video_title": video_title,
                            "author": reply_snippet["authorDisplayName"],
                            "comment": reply_snippet["textDisplay"],
                            "publishedAt": reply_snippet["publishedAt"],
                            "is_reply": True,
                            "reply_to": comment_snippet["authorDisplayName"]  # ai ƒë∆∞·ª£c reply t·ªõi
                        })

        next_page_token = comments_data.get("nextPageToken")
        if not next_page_token:
            break

    return comments_list


# C·∫≠p nh·∫≠t ph·∫ßn crawl ƒë·ªÉ hi·ªÉn th·ªã th√¥ng tin b√¨nh lu·∫≠n
def crawl(url_channel):
    """Crawl th√¥ng tin k√™nh v√† danh s√°ch video."""
    channel_id = get_channel_id(url_channel)
    if not channel_id:
        return None

    params = {"part": "snippet,statistics", "id": channel_id, "key": API_KEY}
    response = requests.get(YOUTUBE_API_URL, params=params)
    data = response.json()

    if "items" not in data or not data["items"]:
        return None

    channel_info = data["items"][0]
    snippet = channel_info["snippet"]
    stats = channel_info["statistics"]

    recent_videos = get_recent_videos(channel_id)

    return {
        "Created": snippet.get("publishedAt", "N/A")[:10],
        "Country": snippet.get("country", "N/A"),
        "Subscribers": int(stats.get("subscriberCount", 0)),
        "Total_videos": int(stats.get("videoCount", 0)),
        "Avatar": snippet["thumbnails"]["high"]["url"] if "thumbnails" in snippet else None,
        "Description": snippet.get("description", "Kh√¥ng c√≥ m√¥ t·∫£"),
        "List_id": channel_id,
        "Recent_videos": recent_videos
    }


def save(file_csv):
    df = pd.DataFrame([file_csv])  # Chuy·ªÉn dictionary th√†nh DataFrame
    csv_bytes = BytesIO()
    df.to_csv(csv_bytes, index=False, encoding="utf-8-sig")  # L∆∞u file v·ªõi UTF-8 (h·ªó tr·ª£ ti·∫øng Vi·ªát)
    csv_bytes.seek(0)
    return csv_bytes


def profile_overview(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    return {
        "Created": df['Created'].iloc[0] if 'Created' in df.columns else "N/A",
        "Add_to_ViralStat": df['Add_to_ViralStat'].iloc[0] if 'Add_to_ViralStat' in df.columns else "N/A",
        "Country": df['Country'].iloc[0] if 'Country' in df.columns else "N/A",
        "Subscribers": df['Subscribers'].iloc[0] if 'Subscribers' in df.columns else 0,
        "Total_videos": df['Total_videos'].iloc[0] if 'Total_videos' in df.columns else 0
    }


def profile_stats(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    return {
        "Subscribers": df['Subscribers'].sum() if 'Subscribers' in df.columns else 0,
        "Total_view": df['Total_view'].sum() if 'Total_view' in df.columns else 0,
        "Avg": df['Avg'].mean() if 'Avg' in df.columns else 0
    }


def analyze_comments(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    # Placeholder for comment analysis logic
    return {
        "Positive_comments": df['Positive_comments'].sum() if 'Positive_comments' in df.columns else 0,
        "Negative_comments": df['Negative_comments'].sum() if 'Negative_comments' in df.columns else 0,
        "Neutral_comments": df['Neutral_comments'].sum() if 'Neutral_comments' in df.columns else 0
    }


def recommend_videos(uploaded_file):
    df = pd.read_csv(uploaded_file)
    st.write("Column names:", df.columns.tolist())  # Print column names for debugging
    # Placeholder for recommendation logic
    return {
        "Recommended_videos": ["Video1", "Video2", "Video3"]  # Example recommendations
    }


def main():
    st.set_page_config(layout="wide")
    st.sidebar.title("Ch·ª©c nƒÉng")
    page = st.sidebar.radio("Ch·ªçn trang", ["Crawl", "Statistical", "ƒê·ªÅ xu·∫•t"])

    if page == "Crawl":
        st.title("Crawl d·ªØ li·ªáu")
        url = st.text_input("Nh·∫≠p URL k√™nh")

        if st.button("T√¨m ki·∫øm"):
            st.session_state["channel_data"] = crawl(url)
            if st.session_state["channel_data"] is None:
                st.error("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu!")
                st.stop()

        # N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu k√™nh
        if "channel_data" in st.session_state:
            data = st.session_state["channel_data"]

            col1, col2 = st.columns([1, 3])
            with col1:
                if data["Avatar"]:
                    response = requests.get(data["Avatar"])
                    image = Image.open(BytesIO(response.content))
                    st.image(image, width=100)
            with col2:
                st.write(f"**Created:** {data['Created']}")
                st.write(f"**Country:** {data['Country']}")
                st.write(f"**Subscribers:** {data['Subscribers']}")
                st.write(f"**Total Videos:** {data['Total_videos']}")
                st.write(f"**Description:** {data['Description']}")
            st.write("**Danh s√°ch 20 video g·∫ßn nh·∫•t**")
            # üü¢ L∆∞u danh s√°ch video v√†o session_state ƒë·ªÉ tr√°nh reload m·∫•t d·ªØ li·ªáu
            if "Recent_videos" not in st.session_state:
                st.session_state["Recent_videos"] = data["Recent_videos"]

            df_videos = pd.DataFrame(st.session_state["Recent_videos"])
            # üü¢ Th√™m ph·∫ßn t·∫£i v·ªÅ CSV

            # üü¢ Dropdown ch·ªçn video
            video_ids = [video["id"] for video in st.session_state["Recent_videos"]]
            selected_video_id = st.selectbox("Ch·ªçn video:", video_ids, format_func=lambda vid: next(
                v["title"] for v in st.session_state["Recent_videos"] if v["id"] == vid))

            # üü¢ Hi·ªÉn th·ªã th√¥ng tin video ƒë√£ ch·ªçn
            #selected_video = next(v for v in st.session_state["Recent_videos"] if v["id"] == selected_video_id)
            def safe_video_generator():
                for v in st.session_state["Recent_videos"]:
                    try:
                        if v["id"] == selected_video_id:
                            yield v
                    except Exception:
                        continue  # B·ªè qua ph·∫ßn t·ª≠ l·ªói

            selected_video = next(safe_video_generator(), None)
            st.write(selected_video)
            try:
                st.write(f"**Ti√™u ƒë·ªÅ video:** {selected_video['title']}")
                st.write(f"**L∆∞·ª£t xem:** {selected_video['views']}")
                st.write(f"**S·ªë b√¨nh lu·∫≠n:** {selected_video['comments']}")
            except Exception as e:
                st.write("Kh√¥ng th·ªÉ hi·ªÉn th·ªã th√¥ng tin video.")

            # üü¢ L·∫•y b√¨nh lu·∫≠n ch·ªâ khi ch∆∞a c√≥
            if "video_comments" not in st.session_state or st.session_state["video_comments"][
                "video_id"] != selected_video_id:
                st.session_state["video_comments"] = {"video_id": selected_video_id,
                                                      "comments": get_all_comments(selected_video_id, data['List_id'],
                                                                                   selected_video['title'])}

            # üü¢ Hi·ªÉn th·ªã b√¨nh lu·∫≠n
            df_comments = pd.DataFrame(st.session_state["video_comments"]["comments"])
            df_comments['clean_comment'] = df_comments['comment'].apply(clean_up_pipeline)
            st.dataframe(df_comments)

            # üü¢ Th√™m ph·∫ßn t·∫£i v·ªÅ CSV

            # üü¢ N√∫t l·∫•y to√†n b·ªô comment c·ªßa t·∫•t c·∫£ video
            if st.button("L·∫•y to√†n b·ªô b√¨nh lu·∫≠n c·ªßa 20 video"):
                all_comments = []
                for video in st.session_state["Recent_videos"]:
                    comments = get_all_comments(video["id"], data["List_id"], video["title"])
                    all_comments.extend(comments)

                # L∆∞u to√†n b·ªô comment v√†o session
                st.session_state["all_video_comments"] = all_comments
                st.success("ƒê√£ l·∫•y xong to√†n b·ªô b√¨nh lu·∫≠n!")

            # üü¢ Hi·ªÉn th·ªã b·∫£ng to√†n b·ªô b√¨nh lu·∫≠n n·∫øu c√≥
            if "all_video_comments" in st.session_state:
                df_all_comments = pd.DataFrame(st.session_state["all_video_comments"])

                if not df_all_comments.empty:
                    st.write("### To√†n b·ªô b√¨nh lu·∫≠n c·ªßa t·∫•t c·∫£ c√°c video")
                    st.dataframe(df_all_comments)

                    # T·∫£i v·ªÅ CSV
            if st.button("üì• T·∫£i file Excel t·ªïng h·ª£p (.xlsx)"):
                excel_bytes = BytesIO()
                with pd.ExcelWriter(excel_bytes, engine="xlsxwriter") as writer:
                    # Sheet 1 - Th√¥ng tin k√™nh
                    channel_info_df = pd.DataFrame([{
                        "Ng√†y t·∫°o": data["Created"],
                        "Qu·ªëc gia": data["Country"],
                        "L∆∞·ª£t ƒëƒÉng k√Ω": data["Subscribers"],
                        "T·ªïng s·ªë video": data["Total_videos"],
                        "M√¥ t·∫£ k√™nh": data["Description"]
                    }])
                    channel_info_df.to_excel(writer, sheet_name="Th√¥ng tin k√™nh", index=False)

                    # Sheet 2 - Danh s√°ch video g·∫ßn ƒë√¢y
                    df_videos.to_excel(writer, sheet_name="Video g·∫ßn ƒë√¢y", index=False)

                    # Sheet 3 - Danh s√°ch b√¨nh lu·∫≠n (∆∞u ti√™n l·∫•y to√†n b·ªô n·∫øu c√≥)
                    df_all_comments = pd.DataFrame(
                        st.session_state["all_video_comments"]
                    ) if "all_video_comments" in st.session_state else df_comments
                    df_all_comments['clean_comment'] = df_all_comments['comment'].apply(clean_up_pipeline)
                    df_all_comments.to_excel(writer, sheet_name="B√¨nh lu·∫≠n", index=False)

                excel_bytes.seek(0)
                st.download_button(
                    label="üìÑ T·∫£i xu·ªëng file Excel",
                    data=excel_bytes,
                    file_name="youtube_data.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    elif page == "Statistical":
        st.title("Th·ªëng k√™ Ph√¢n t√≠ch YouTube")
        uploaded_file = st.file_uploader("T·∫£i l√™n file Excel (.xlsx)", type=["xlsx"])

        if uploaded_file:
            video_data = pd.read_excel(uploaded_file, sheet_name="Video g·∫ßn ƒë√¢y")
            channel_info = pd.read_excel(uploaded_file, sheet_name="Th√¥ng tin k√™nh")
            video_comment = pd.read_excel(uploaded_file, sheet_name="B√¨nh lu·∫≠n")

            video_comment['clean_comment'] = video_comment['clean_comment'].astype(str)

            #################
            cleaned = clean_up_pipeline(channel_info['M√¥ t·∫£ k√™nh'][0])
            label, words = model_title.classify_sentiment(cleaned)
            st.write(label)
            # st.write(words)
            if label == '0':
                video_comment['label'] = video_comment['clean_comment'].apply(
                    lambda x: model_football.classify_sentiment(x)[0])
            else:
                video_comment['label'] = video_comment['clean_comment'].apply(
                    lambda x: model_info.classify_sentiment(x)[0])





            ##################
            video_data['published_date'] = pd.to_datetime(video_data['published_date'])
            video_data['title_length'] = video_data['title'].apply(lambda x: len(str(x)))
            video_data['comment_view_ratio'] = video_data['comments'] / video_data['views']
            video_data['month'] = video_data['published_date'].dt.to_period('M')
            video_data['week'] = video_data['published_date'].dt.to_period('W')
            video_data['day'] = video_data['published_date'].dt.to_period('D')
            video_data['short_title'] = video_data['title'].apply(lambda x: (x[:40] + '...') if len(str(x)) > 40 else x)

            # D√≤ng ti√™u ƒë·ªÅ v·ªõi ch·ªØ tr√°i - ph·∫£i
            c1, c2 = st.columns([1, 1])

            with c1:
                st.markdown("### üìä T·ªïng quan k√™nh")

            with c2:
                st.markdown("### üîç Theo d√µi")

            tab1, tab2, tab3, tab4, tab5, tab6 , tab7, tab8, tab9= st.tabs(
                ["T·ªïng quan", "Ph·ªï bi·∫øn", "T·ª∑ l·ªá t∆∞∆°ng t√°c", "Hi·ªáu su·∫•t", "Ph√¢n nh√≥m", "T·ªâ l·ªá t·ªïng quan",'T·ªâ l·ªá theo th·ªùi gian', "Top video vi ph·∫°m",
                 "ƒê√°nh gi√° t·ªïng th·ªÉ"])

            with tab1:
                st.subheader("Th√¥ng tin k√™nh")
                st.write(f"**Ng√†y t·∫°o:** {channel_info.iloc[0]['Ng√†y t·∫°o']}")
                st.write(f"**Qu·ªëc gia:** {channel_info.iloc[0]['Qu·ªëc gia']}")
                st.write(f"**L∆∞·ª£t ƒëƒÉng k√Ω:** {channel_info.iloc[0]['L∆∞·ª£t ƒëƒÉng k√Ω']:,}")
                st.write(f"**T·ªïng s·ªë video:** {channel_info.iloc[0]['T·ªïng s·ªë video']:,}")
                st.write(f"**M√¥ t·∫£:** {channel_info.iloc[0]['M√¥ t·∫£ k√™nh']}")

            with tab2:
                st.markdown("## üìä So s√°nh Top 10 Videos (M·ªü r·ªông ngang, ch·ªØ nh·ªè)")

                col1, col2 = st.columns([1, 1])  # gi·ªØ nguy√™n chia 2 c·ªôt b·∫±ng nhau

                with col1:
                    st.markdown("### üëÅÔ∏è Views")
                    top10_views = video_data.sort_values(by='views', ascending=False).head(10)
                    fig1 = plt.figure(figsize=(7, 3))  # r·ªông h∆°n, th·∫•p h∆°n
                    sns.barplot(data=top10_views, y='short_title', x='views', palette='Blues_r')
                    plt.title('Top 10 by Views', fontsize=10)
                    plt.xlabel('Views', fontsize=9)
                    plt.ylabel('')
                    plt.xticks(fontsize=8)
                    plt.yticks(fontsize=7)
                    plt.tight_layout()
                    st.pyplot(fig1)

                with col2:
                    st.markdown("### üí¨ Comments")
                    top10_comments = video_data.sort_values(by='comments', ascending=False).head(10)
                    fig2 = plt.figure(figsize=(7, 3))  # r·ªông h∆°n, th·∫•p h∆°n
                    sns.barplot(data=top10_comments, y='short_title', x='comments', palette='Oranges_r')
                    plt.title('Top 10 by Comments', fontsize=10)
                    plt.xlabel('Comments', fontsize=9)
                    plt.ylabel('')
                    plt.xticks(fontsize=8)
                    plt.yticks(fontsize=7)
                    plt.tight_layout()
                    st.pyplot(fig2)

            with tab3:
                with st.expander("Theo b√¨nh lu·∫≠n v√† l∆∞·ª£t xem"):
                    st.markdown("### Bubble chart: Views vs Comments (Size = Comments/Views)")

                    # T·∫°o layout v·ªõi 2 c·ªôt
                    col1, col2 = st.columns([7, 3])  # C·ªôt b√™n tr√°i chi·∫øm 50% v√† c·ªôt b√™n ph·∫£i chi·∫øm 50%

                    # --- C·ªôt 1: Bi·ªÉu ƒë·ªì Bubble Chart ---
                    with col1:
                        plt.figure(figsize=(10, 6))  # K√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
                        sizes = ((video_data['comments'] / video_data['views']) * 300000).clip(10, 5000)
                        plt.scatter(video_data['views'], video_data['comments'], s=sizes, alpha=0.5, edgecolors='w')

                        for i in range(len(video_data)):
                            short_title = video_data['short_title'].iloc[i]
                            plt.annotate(short_title,
                                         (video_data['views'].iloc[i], video_data['comments'].iloc[i]),
                                         fontsize=8, alpha=0.6)

                        plt.title('Bubble Chart: Views vs Comments (Size = Comments/Views)', fontsize=12)
                        plt.xlabel('Views', fontsize=10)
                        plt.ylabel('Comments', fontsize=10)
                        plt.grid(True)
                        plt.tight_layout()
                        st.pyplot(plt)
                        # T·∫°o ƒë∆∞·ªùng k·∫ª ph√¢n c√°ch gi·ªØa hai c·ªôt
                    st.markdown(
                        """
                        <style>
                        .divider {
                            border-left: 2px solid #D3D3D3;
                            height: 100%;
                            margin-left: 10px;
                            margin-right: 10px;
                        }
                        </style>
                        """, unsafe_allow_html=True
                    )
                    st.markdown("<div class='divider'></div>", unsafe_allow_html=True)
                    # --- C·ªôt 2: Hi·ªÉn th·ªã ch·ªØ "Sl" ---
                    with col2:
                        st.markdown("### Sl")
                        st.write("ƒê√¢y l√† ph·∫ßn d√†nh cho ch·ªØ 'Sl'. B·∫°n c√≥ th·ªÉ thay ƒë·ªïi n·ªôi dung theo y√™u c·∫ßu.")

                with st.expander("T·ªâ l·ªá t∆∞∆°ng t√°c theo ƒë·ªô d√†i ti√™u ƒë·ªÅ"):
                    st.markdown("### Scatter: Title length vs Comments/Views")

                    # T·∫°o layout v·ªõi 2 c·ªôt, bi·ªÉu ƒë·ªì chi·∫øm 70%, ch·ªØ "Sl" chi·∫øm 30%
                    col1, col2 = st.columns([7, 3])  # C·ªôt b√™n tr√°i chi·∫øm 70% v√† c·ªôt b√™n ph·∫£i chi·∫øm 30%

                    # --- C·ªôt 1: Bi·ªÉu ƒë·ªì Scatter ---
                    with col1:
                        video_data['comment_view_ratio'] = video_data['comments'] / video_data['views']

                        plt.figure(figsize=(10, 6))  # K√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì
                        sns.scatterplot(data=video_data, x='title_length', y='comment_view_ratio', color='green',
                                        marker='o')

                        plt.title('Title Length vs Comment/View Ratio', fontsize=12)
                        plt.xlabel('Title Length', fontsize=10)
                        plt.ylabel('Comment/View Ratio', fontsize=10)
                        plt.grid(True)
                        plt.tight_layout()
                        st.pyplot(plt)

                    # --- C·ªôt 2: Hi·ªÉn th·ªã ch·ªØ "Sl" ---
                    with col2:
                        # Th√™m ƒë∆∞·ªùng ph√¢n c√°ch gi·ªØa c·ªôt 1 v√† c·ªôt 2
                        st.markdown(
                            """
                            <style>
                            .divider {
                                border-left: 2px solid #D3D3D3;
                                height: 100%;
                                margin-left: 10px;
                                margin-right: 10px;
                            }
                            </style>
                            """, unsafe_allow_html=True
                        )
                        st.markdown("<div class='divider'></div>", unsafe_allow_html=True)  # Hi·ªÉn th·ªã ƒë∆∞·ªùng ph√¢n c√°ch

                        # N·ªôi dung c·ªôt 2
                        st.markdown("### Sl")
                        st.write("ƒê√¢y l√† ph·∫ßn d√†nh cho ch·ªØ 'Sl'. B·∫°n c√≥ th·ªÉ thay ƒë·ªïi n·ªôi dung theo y√™u c·∫ßu.")

            with tab4:
                st.markdown("### üìä Ph√¢n t√≠ch s·ªë video v√† l∆∞·ª£t t∆∞∆°ng t√°c theo th·ªùi gian")
                # --- 6. S·ªë video theo th√°ng, tu·∫ßn, ng√†y ---

                # Monthly stats (c√≥ ƒë·∫ßy ƒë·ªß th√°ng)
                st.markdown("")
                full_month_range = pd.period_range(start=video_data['month'].min(), end=video_data['month'].max(),
                                                   freq='M')
                monthly_stats = video_data.groupby('month').agg({
                    'title': 'count',
                    'views': 'sum',
                    'comments': 'sum'
                }).rename(columns={'title': 'video_count'})
                monthly_stats = monthly_stats.reindex(full_month_range, fill_value=0)

                # Weekly stats (c√≥ ƒë·∫ßy ƒë·ªß tu·∫ßn)
                full_week_range = pd.period_range(start=video_data['week'].min(), end=video_data['week'].max(),
                                                  freq='W')
                weekly_stats = video_data.groupby('week').agg({
                    'title': 'count',
                    'views': 'sum',
                    'comments': 'sum'
                }).rename(columns={'title': 'video_count'})
                weekly_stats = weekly_stats.reindex(full_week_range, fill_value=0)

                # Daily stats (c√≥ ƒë·∫ßy ƒë·ªß ng√†y)
                full_day_range = pd.period_range(start=video_data['day'].min(), end=video_data['day'].max(), freq='D')
                daily_stats = video_data.groupby('day').agg({
                    'title': 'count',
                    'views': 'sum',
                    'comments': 'sum'
                }).rename(columns={'title': 'video_count'})

                daily_stats = daily_stats.reindex(full_day_range, fill_value=0)
                # üéØ T√≠nh trung b√¨nh views/comments CH·ªà CHO NH·ªÆNG NG√ÄY C√ì VIDEO
                # (kh√¥ng d√πng reindex)

                monthly_avg = monthly_stats[monthly_stats['video_count'] > 0]
                weekly_avg = weekly_stats[weekly_stats['video_count'] > 0]
                daily_avg = daily_stats[daily_stats['video_count'] > 0]

                monthly_avg['avg_views_per_video'] = monthly_avg['views'] / monthly_avg['video_count']
                weekly_avg['avg_views_per_video'] = weekly_avg['views'] / weekly_avg['video_count']
                daily_avg['avg_views_per_video'] = daily_avg['views'] / daily_avg['video_count']

                monthly_avg['avg_comments_per_video'] = monthly_avg['comments'] / monthly_avg['video_count']
                weekly_avg['avg_comments_per_video'] = weekly_avg['comments'] / weekly_avg['video_count']
                daily_avg['avg_comments_per_video'] = daily_avg['comments'] / daily_avg['video_count']

                # S·ªë video theo ng√†y

                # --- Expander: Th·ªëng k√™ theo ng√†y ---
                with st.expander("üìÖ Th·ªëng k√™ theo ng√†y", expanded=False):
                    # 6.3 Daily - S·ªë video theo ng√†y
                    st.markdown("S·ªë video tr√™n ng√†y")
                    plt.figure(figsize=(20, 6))
                    ax = daily_stats['video_count'].plot(kind='bar', color='lightcoral')
                    plt.title('Number of Videos per Day')
                    plt.tight_layout()
                    st.pyplot(plt)

                    # --- Daily ---
                    st.markdown("S·ªë views tr√™n ng√†y")
                    daily_stats_nonzero = daily_stats[daily_stats['video_count'] > 0].copy()
                    daily_stats_nonzero['avg_views_per_video'] = daily_stats_nonzero['views'] / daily_stats_nonzero[
                        'video_count']
                    fig, ax = plt.subplots(figsize=(20, 6))
                    ax.plot(daily_stats_nonzero.index.to_timestamp(), daily_stats_nonzero['avg_views_per_video'],
                            marker='o', color='green', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Views per Video per Day')
                    plt.xlabel('Day')
                    plt.ylabel('Avg Views per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Daily ---
                    st.markdown("S·ªë comments tr√™n ng√†y")
                    daily_stats_nonzero['avg_comments_per_video'] = daily_stats_nonzero['comments'] / \
                                                                    daily_stats_nonzero[
                                                                        'video_count']
                    fig, ax = plt.subplots(figsize=(20, 6))
                    ax.plot(daily_stats_nonzero.index.to_timestamp(), daily_stats_nonzero['avg_comments_per_video'],
                            marker='o', color='red', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Comments per Video per Day')
                    plt.xlabel('Day')
                    plt.ylabel('Avg Comments per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Expander: Th·ªëng k√™ theo tu·∫ßn ---
                with st.expander("üìà Th·ªëng k√™ theo tu·∫ßn", expanded=False):
                    # 6.2 Weekly - S·ªë video theo tu·∫ßn
                    st.markdown("S·ªë video tr√™n tu·∫ßn")
                    plt.figure(figsize=(14, 6))
                    ax = weekly_stats['video_count'].plot(kind='bar', color='lightgreen')
                    plt.title('Number of Videos per Week')
                    plt.tight_layout()
                    st.pyplot(plt)

                    # --- Weekly ---
                    st.markdown("S·ªë views tr√™n tu·∫ßn")
                    weekly_stats_nonzero = weekly_stats[weekly_stats['video_count'] > 0].copy()
                    weekly_stats_nonzero['avg_views_per_video'] = weekly_stats_nonzero['views'] / weekly_stats_nonzero[
                        'video_count']
                    fig, ax = plt.subplots(figsize=(14, 6))
                    ax.plot(weekly_stats_nonzero.index.to_timestamp(), weekly_stats_nonzero['avg_views_per_video'],
                            marker='o', color='blue', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Views per Video per Week')
                    plt.xlabel('Week')
                    plt.ylabel('Avg Views per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Weekly ---
                    st.markdown("S·ªë comments tr√™n tu·∫ßn")
                    weekly_stats_nonzero['avg_comments_per_video'] = weekly_stats_nonzero['comments'] / \
                                                                     weekly_stats_nonzero['video_count']
                    fig, ax = plt.subplots(figsize=(14, 6))
                    ax.plot(weekly_stats_nonzero.index.to_timestamp(), weekly_stats_nonzero['avg_comments_per_video'],
                            marker='o', color='purple', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
                    plt.xticks(rotation=45)
                    plt.title('Average Comments per Video per Week')
                    plt.xlabel('Week')
                    plt.ylabel('Avg Comments per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)
                    # --- Expander: Th·ªëng k√™ theo th√°ng ---
                with st.expander("üóìÔ∏è Th·ªëng k√™ theo th√°ng", expanded=False):
                    # 6.1 Monthly - S·ªë video theo th√°ng
                    st.markdown("S·ªë video tr√™n th√°ng")
                    plt.figure(figsize=(10, 5))
                    ax = monthly_stats['video_count'].plot(kind='bar', color='skyblue')
                    plt.title('Number of Videos per Month')
                    plt.tight_layout()
                    st.pyplot(plt)

                    # --- Monthly ---
                    st.markdown("S·ªë Views tr√™n th√°ng")
                    monthly_stats_nonzero = monthly_stats[monthly_stats['video_count'] > 0].copy()
                    monthly_stats_nonzero['avg_views_per_video'] = monthly_stats_nonzero['views'] / \
                                                                   monthly_stats_nonzero[
                                                                       'video_count']
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(monthly_stats_nonzero.index.to_timestamp(), monthly_stats_nonzero['avg_views_per_video'],
                            marker='o', color='orange', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.MonthLocator())
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
                    plt.xticks(rotation=45)
                    plt.title('Average Views per Video per Month')
                    plt.xlabel('Month')
                    plt.ylabel('Avg Views per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

                    # --- Monthly ---
                    st.markdown("S·ªë comments tr√™n th√°ng")
                    monthly_stats_nonzero['avg_comments_per_video'] = monthly_stats_nonzero['comments'] / \
                                                                      monthly_stats_nonzero['video_count']
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.plot(monthly_stats_nonzero.index.to_timestamp(), monthly_stats_nonzero['avg_comments_per_video'],
                            marker='o', color='green', linestyle='-')
                    ax.xaxis.set_major_locator(mdates.MonthLocator())
                    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
                    plt.xticks(rotation=45)
                    plt.title('Average Comments per Video per Month')
                    plt.xlabel('Month')
                    plt.ylabel('Avg Comments per Video')
                    plt.grid(True)
                    plt.tight_layout()
                    st.pyplot(fig)

            with tab5:
                st.markdown("KMeans Clustering: Views vs Comments")
                features = video_data[['views', 'comments']]
                scaler = StandardScaler()
                scaled_features = scaler.fit_transform(features)
                kmeans = KMeans(n_clusters=4, random_state=42)
                video_data['cluster'] = kmeans.fit_predict(scaled_features)

                plt.figure(figsize=(10, 6))
                sns.scatterplot(data=video_data, x='views', y='comments', hue='cluster', palette='Set2')
                plt.title('KMeans Clustering')
                st.pyplot(plt)

                st.markdown("""
                **Nh√≥m ph√¢n lo·∫°i:**
                - Nh√≥m 0: View cao, comment cao
                - Nh√≥m 1: View cao, comment th·∫•p
                - Nh√≥m 2: View th·∫•p, comment cao
                - Nh√≥m 3: View th·∫•p, comment th·∫•p
                """)

            with tab6:
                st.markdown("B·∫£ng ")
                st.subheader("D·ªØ li·ªáu b·∫£ng B√¨nh lu·∫≠n")
                st.write(label)

                # T√≠nh to√°n s·ªë l∆∞·ª£ng c√°c gi√° tr·ªã trong c·ªôt 'label'
                label_counts = video_comment['label'].value_counts().sort_index()
                labels = ['T√≠ch c·ª±c' if i == 'b√¨nh th∆∞·ªùng' else 'Ti√™u c·ª±c' for i in label_counts.index]

                # T·∫°o layout 2 c·ªôt
                col1, col2 = st.columns(2)

                with col1:
                    # Bi·ªÉu ƒë·ªì tr√≤n trong c·ªôt b√™n tr√°i
                    fig, ax = plt.subplots(figsize=(2.5, 2.5))  # ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc t√πy √Ω
                    ax.pie(label_counts, labels=labels, autopct='%.1f%%',
                           colors=['#66b3ff', '#ff6666'], startangle=140, textprops={'fontsize': 5})
                    ax.set_title('T·ª∑ l·ªá c·∫£m x√∫c', fontsize=7)
                    st.pyplot(fig)

                with col2:
                    # Ph·∫ßn ch·ªØ ho·∫∑c n·ªôi dung b√™n ph·∫£i
                    st.markdown("### Ph√¢n t√≠ch c·∫£m x√∫c")
                    st.write(
                        "Bi·ªÉu ƒë·ªì b√™n tr√°i th·ªÉ hi·ªán t·ª∑ l·ªá ph·∫ßn trƒÉm c√°c b√¨nh lu·∫≠n t√≠ch c·ª±c v√† ti√™u c·ª±c. "
                        "D·ª±a v√†o d·ªØ li·ªáu, b·∫°n c√≥ th·ªÉ nh·∫≠n bi·∫øt s·ª± ph√¢n b·ªë c·∫£m x√∫c trong t·∫≠p b√¨nh lu·∫≠n."
                    )

            with tab7:

                # ƒê·∫£m b·∫£o c·ªôt 'publishedAt' l√† ki·ªÉu datetime
                video_comment['publishedAt'] = pd.to_datetime(video_comment['publishedAt'])

                # T·∫°o c·ªôt "3 ng√†y"
                video_comment['3_days'] = video_comment['publishedAt'].dt.to_period('D').apply(lambda r: r.start_time).dt.floor(
                    'D') + pd.to_timedelta(video_comment['publishedAt'].dt.day // 3 * 3, unit='D')

                # ƒê·∫øm s·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo kho·∫£ng 3 ng√†y v√† nh√£n
                count_by_3_days = video_comment.groupby(['3_days', 'label']).size().unstack(fill_value=0)

                col1, col2 = st.columns([3, 2])  # 3 ph·∫ßn cho bi·ªÉu ƒë·ªì, 2 ph·∫ßn cho n·ªôi dung kh√°c (t·ªïng = 5 -> 60%)

                with col1:
                    fig, ax = plt.subplots(figsize=(6, 4))
                    count_by_3_days.plot(kind='bar', ax=ax, color=['#66b3ff', '#ff6666'])

                    ax.set_xlabel('Ng√†y (M·ªói 3 ng√†y)', fontsize=8)
                    ax.set_ylabel('S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n', fontsize=8)
                    ax.set_title('S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo m·ªói 3 ng√†y v√† nh√£n (0: B√¨nh th∆∞·ªùng, 1: Toxic)', fontsize=9)
                    ax.tick_params(axis='x', labelrotation=45, labelsize=7)
                    ax.tick_params(axis='y', labelsize=7)
                    ax.legend(title='Label', labels=count_by_3_days.columns.astype(str), fontsize=7, title_fontsize=8)

                    plt.tight_layout()
                    st.pyplot(fig)

                with col2:
                    st.markdown("### Th·ªëng k√™")
                    st.markdown("- Bi·ªÉu ƒë·ªì th·ªÉ hi·ªán s·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo t·ª´ng kho·∫£ng 3 ng√†y.")
                    st.markdown("- M√†u xanh: B√¨nh th∆∞·ªùng, M√†u ƒë·ªè: Toxic.")

            with tab8:
                # T√≠nh t·ªïng s·ªë b√¨nh lu·∫≠n v√† s·ªë b√¨nh lu·∫≠n c√≥ label != 0 theo t·ª´ng video
                total_by_video = video_comment.groupby('video_title').size()
                toxic_by_video = video_comment[video_comment['label'] != 'b√¨nh th∆∞·ªùng'].groupby('video_title').size()

                # T√≠nh t·ª∑ l·ªá % v√† ch·ªçn top 10 video c√≥ t·ª∑ l·ªá toxic cao nh·∫•t
                toxic_percent = (toxic_by_video / total_by_video * 100).fillna(0)
                top10_videos = toxic_percent.sort_values(ascending=False).head(10)

                # Layout chia 2 c·ªôt: 60% - 40%
                col1, col2 = st.columns([3, 2])

                with col1:
                    fig, ax = plt.subplots(figsize=(6, 4))
                    ax.bar(range(1, 11), top10_videos.values, color='#ff6666')
                    ax.set_xticks(range(1, 11))
                    ax.set_xticklabels(range(1, 11))
                    ax.set_ylabel('T·ª∑ l·ªá % b√¨nh lu·∫≠n toxic', fontsize=9)
                    ax.set_title('Top 10 video c√≥ t·ª∑ l·ªá b√¨nh lu·∫≠n toxic cao nh·∫•t', fontsize=10)
                    ax.tick_params(labelsize=8)
                    plt.tight_layout()
                    st.pyplot(fig)

                with col2:
                    st.markdown("**Danh s√°ch video t∆∞∆°ng ·ª©ng:**")
                    video_labels = top10_videos.index.tolist()
                    for i, title in enumerate(video_labels, start=1):
                        st.markdown(f"{i}. {title}")

            with tab9:

                # T√≠nh t·ªïng s·ªë b√¨nh lu·∫≠n v√† s·ªë b√¨nh lu·∫≠n c√≥ label != 0 theo t·ª´ng video
                total_by_video = video_comment.groupby('video_title').size()
                toxic_by_video = video_comment[video_comment['label'] != 'b√¨nh th∆∞·ªùng'].groupby('video_title').size()

                # T√≠nh t·ª∑ l·ªá % v√† x√°c ƒë·ªãnh video n√†o c√≥ t·ª∑ l·ªá toxic > 11%
                toxic_percent = (toxic_by_video / total_by_video * 100).fillna(0)

                # ƒê√°nh d·∫•u video ti√™u c·ª±c (t·ª∑ l·ªá toxic > 11%)
                toxic_videos = toxic_percent[toxic_percent > 11].index
                non_toxic_videos = toxic_percent[toxic_percent <= 11].index

                # T·∫°o m·ªôt Series v·ªõi c√°c video ti√™u c·ª±c v√† kh√¥ng ti√™u c·ª±c
                video_labels = ['Ti√™u c·ª±c' if video in toxic_videos else 'Kh√¥ng ti√™u c·ª±c' for video in
                                video_comment['video_title']]
                labels_count = pd.Series(video_labels).value_counts()

                # T·∫°o layout 2 c·ªôt v·ªõi t·ª∑ l·ªá 3:2 (60% v√† 40%)
                col1, col2 = st.columns([1, 1])

                with col1:
                    fig, ax = plt.subplots(figsize=(3, 3))
                    ax.pie(labels_count, labels=labels_count.index, autopct='%1.1f%%', startangle=90,
                           colors=['#ff6666', '#66b3ff'])
                    ax.set_title('T·ª∑ l·ªá video ti√™u c·ª±c vs kh√¥ng ti√™u c·ª±c', fontsize=10)
                    plt.tight_layout()
                    st.pyplot(fig)

                with col2:
                    st.markdown("**Ph√¢n lo·∫°i video:**")
                    for label, count in labels_count.items():
                        st.markdown(f"- **{label}**: {count} video")



            plt.show()
            # --- K·∫øt th√∫c ---
            print("\n‚úÖ ƒê√£ hi·ªÉn th·ªã to√†n b·ªô bi·ªÉu ƒë·ªì!")


    elif page == "ƒê·ªÅ xu·∫•t":
        st.title("ƒê·ªÅ xu·∫•t video")
        uploaded_file = st.file_uploader("T·∫£i l√™n file CSV", type=["csv"])
        if uploaded_file:
            recommendation_data = recommend_videos(uploaded_file)

            st.markdown("**Video Recommendations**")
            for video in recommendation_data["Recommended_videos"]:
                st.text(video)


if __name__ == "__main__":
    main()